\section{Related work}
\label{sec:related}

A large number of domain adaptation methods have been proposed over the recent years, and here we focus on the most related ones. Multiple methods perform unsupervised domain adaptation by matching the feature distributions in the source and the target domains. Some approaches perform this by reweighing or selecting samples from the source domain \cite{Borgwardt06,Huang06,Gong13}, while others seek an explicit feature space transformation that would map source distribution into the target ones \cite{Pan11,Gopalan11,Baktashmotlagh13}. An important aspect of the distribution matching approach is the way the (dis)similarity between distributions is measured.  Here, one popular choice is matching the distribution means in the kernel-reproducing Hilbert space \cite{Borgwardt06,Huang06}, whereas \cite{Gong12,Fernando13} map the principal axes associated with each of the distributions. Our approach also attempts to match feature space distributions, however this is accomplished by modifying the feature representation itself rather than by reweighing or geometric transformation. Also, our method uses (implicitly) a rather different way to measure the disparity between distributions based on their separability by a deep discriminatively-trained classifier.

Several approaches perform gradual transition from the source to the target domain \cite{Gopalan11,Gong12} by a gradual change of the training distribution. Among these methods, \cite{Chopra13} does this in a ``deep'' way by the layerwise training of a sequence of deep autoencoders, while gradually replacing source-domain samples with target-domain samples. This improves over a similar approach of \cite{Glorot11} that simply trains a single deep autoencoder for both domains. In both approaches, the actual classifier/predictor is learned in a separate step using the feature representation learned by autoencoder(s). In contrast to \cite{Glorot11,Chopra13}, our approach performs feature learning, domain adaptation and classifier learning jointly, in a unified architecture, and using a single learning algorithm (backpropagation). We therefore argue that our approach is simpler (both conceptually and in terms of its implementation). Our method also achieves considerably better results on the popular {\sc Office} benchmark.

While the above approaches perform unsupervised domain adaptation, there are approaches that perform {\em supervised} domain adaptation by exploiting labeled data from the target domain. In the context of deep feed-forward architectures, such data can be used to ``fine-tune'' the network trained on the source domain~\cite{Zeiler13,Oquab14,Babenko14}. Our approach does not require labeled target-domain data. At the same time, it can easily incorporate such data when it is available.

An idea related to ours is described in \cite{Goodfellow14}. While their goal is quite different (building generative deep networks that can synthesize samples), the way they measure and minimize the discrepancy between the distribution of the training data and the distribution of the synthesized data is very similar to the way our architecture measures and minimizes the discrepancy between feature distributions for the two domains.

Finally, a recent and concurrent report by \cite{Tzeng14} also focuses on domain adaptation in feed-forward networks. Their set of techniques measures and minimizes the distance of the data means across domains. This approach may be regarded as a ``first-order'' approximation to our approach, which seeks a tighter alignment between distributions.