\section{Body Part Detectors}
\label{section:unary}
\setlength{\belowdisplayskip}{1pt} \setlength{\belowdisplayshortskip}{1pt}
\setlength{\abovedisplayskip}{1pt} \setlength{\abovedisplayshortskip}{1pt}

%% Here we introduce deep learning-based part detection models. First, we
%% describe our proposal-based model inspired by Fast
%% R-CNN~\cite{girshickICCV15fastrcnn}
%% (\ref{sec:R-CNN-for-pose-estimation}). Then, we introduce our novel
%% model that outputs dense part detection scoremaps at the fine image
%% resolution (\ref{sec:Dense-unary}). Finally, we evaluate both
%% detection models on two prominent single person pose estimation
%% benchmarks and show significant performance improvements over the
%% state of the art.

We first introduce our deep learning-based part detection models and
then evaluate them on two prominent benchmarks thereby significantly
outperforming state of the art.

\subsection{Adapted Fast R-CNN ($\rcnn$)}
\label{sec:R-CNN-for-pose-estimation}
To obtain strong part detectors we adapt Fast
R-CNN~\cite{girshickICCV15fastrcnn}.
%% FR-CNN takes as input an image and set of class-independent region
%% proposals generated by selective search~\cite{Uijlings13}. First, an
%% image is processed with several network layers to produce a
%% convolutional scoremap. Next, for each proposal window a fixed-length
%% feature vector is extracted from the feature map and fed into
%% fully-connected (FC) layers. The outputs are softmax probabilities over
%% all classes and refined bounding boxes. To adapt FR-CNN for part
%% detection we alter it in two ways: {\it 1)} proposal generation and
%% {\it 2)} detection region size. The adapted version is called~$\rcnn$
%% throughout the paper.
FR-CNN takes as input an image and set of class-independent region
proposals~\cite{Uijlings13}
%% generated by selective search~\cite{Uijlings13}
and outputs the softmax probabilities over all classes and refined
bounding boxes. To adapt FR-CNN for part detection we alter it in two
ways: {\it 1)} proposal generation and {\it 2)} detection region
size. The adapted version is called~$\rcnn$ throughout the paper.

\myparagraph{Detection proposals.} Generating object proposals is
essential for FR-CNN, meanwhile detecting body parts is challenging
due to their small size and high intra-class variability.
%caused by articulation, shape, appearance and viewpoint changes.
We use DPM-based part detectors \cite{pishchulin13iccv} for proposal
generation.
%% The rotation space of each body part is discretized into $16$
%% orientation bins, obtained by clustering of absolute rotations of
%% training samples. Training samples are assigned to the corresponding
%% rotation bin and a $16$ component deformable part model (DPM) is
%% trained from image patches extracted around body joints. This results
%% in body part detectors based on rotation-dependent mixtures. Finally,
We collect $K$ top-scoring detections by each part detector in a
common pool of $N$ part-independent proposals and use these proposals as
input to \rcnn. $N$ is $2,000$ in case of single and $20,000$ in case
of multiple people.

\myparagraph{Larger context.} Increasing the size of DPM detections by
upscaling every bounding box by a fixed factor allows to capture more
context around each part. In Sec.~\ref{sec:experiments:unary} we
evaluate the influence of upscaling and show that using larger context
around parts is crucial for best performance.

\myparagraph{Details.} Following standard FR-CNN training procedure
ImageNet models are finetuned on pose estimation task.
%% Using data augmentation and selecting optimal parameters
%% (Sec.~\ref{sec:unary:rcnn}) , such as learning rate, number of SGD
%% iterations, assignment of positive/negative labels, and bounding box
%% regression in FR-CNN significantly improves the
%% performance. Furthermore, using deeper architectures, such as
%% VGG~\cite{Simonyan14c} lead to better results compared to smaller
%% networks like AlexNet~\cite{krizhevsky12nips}. We evaluate different
%% network architectures and several important parameters in
%% Sec.~\ref{sec:experiments:unary} and provide more detailed evaluation
%% in the supplementary material. Finally,
Center of a predicted bounding box is used for body part location
prediction. See Appendix~\ref{seq:supplemental:lsp} for detailed parameter analysis.

%% \myparagraph{Further details.} The SPLP problem is NP-hard, in order
%% to solve instances of this problem efficiently, we select a subset of
%% representative detections by the R-CNN softmax output.  More
%% specifically, for each detection $d$, we take the maximum of all the
%% $p_{dc}$ as its confidence.  Detection subset then consists of the top
%% $n$ detections with the highest confidence.  As shown in
%% Sec.~\ref{sec:results}, we consider two detection subsets $|D|= 60$
%% and $|D| = 100$.  In addition, the $x_{dc}$ variables are constrained
%% to 0 during the optimization, if $p_{dc} \leq 0.2$.


% we eliminate detections that all the body part probabilities smaller than
% As shown in Sec.~\ref{sec:results}, given the strong RCNN part detector,
% a small subset of detection $(|D| = 60, |D|=100)$ is sufficient as
% the recall achieves $93.4\%$ and $94.5\%$, respectively.
% we select a representative global subset of
% $|D|$ top scoring detections. To that end for each proposal window we
% compute a probability score for each of the $|C|=14$ body parts. Then
% we increase the detection score threshold and eliminate all detections
% $d$ for which the scores of all part classes $c$ fall below the
% threshold. We continue until the desired number of detections is left.
% In our experiments we use $|D|=60$ and $|D|=100$ detections. In
% Sec.~\ref{sec:results} we evaluate the recall of the reduced set of
% detections. In order to further reduce the optimization run time we
% set the detection score below the minimum threshold value to 0. We
% choose $0.2$ for our experiments and evaluate the performance of unaries
% with and without the minimum probability value in
% Sec.~\ref{sec:results}.

\subsection{Dense Architecture (\dense)}
\label{sec:Dense-unary}
Using proposals for body part detection may be sub-optimal.
We thus develop a fully convolutional architecture for computing part
probability scoremaps.
%% One of the major drawbacks of using RCNN is reliance on
%% proposals. On the other hand approach described in
%% \cite{tompson14nips} and \cite{Tompson:2015:EOL} uses fully
%% convolutional CNN for part detectors.

\myparagraph{Stride.} We build on VGG~\cite{Simonyan14c}. Fully
convolutional VGG has stride of 32 px -- too coarse for precise part
localization. We thus use hole algorithm~\cite{chen14semantic} to
reduce the stride to 8 px.

\myparagraph{Scale.} Selecting image scale is crucial. We
%% In RCNN we can
%% vary the size of proposals, whereas in CNN the size of receptive field
%% remains fixed (224 pixels for VGG), so
 found that scaling to a standing height of $340$ px performs
 best: %$400\times400$ 
 VGG receptive field sees entire
 body to disambiguate body parts.

\myparagraph{Loss function.}
%% Part detection can be viewed as a multi-class classification problem, where
%% typically softmax is used with multinomial logistic loss. In such formulation
%% each class corresponds to a part and we additionally have one class for no part
%% (background).
We start with a softmax loss that outputs probabilities for each body
part and background. The downside is inability
%% to model situations where for a particular location more than one part
%% can probabilities greater than 0.5, such as in case of
%% foreshortening.
to assign probabilities above $0.5$ to several close-by body parts. We
thus re-formulate the detection as multi-label classification, where
at each location a separate set of probability distributions is
estimated for each part.
%% \cite{tompson14nips}
%% uses MSE objective function, however our experiments showed
%% significant performance degradation (see supplementary materials).
We use sigmoid activation function on the output neurons and cross
entropy loss. We found this loss to perform better than softmax and
converge much faster compared to MSE~\cite{tompson14nips}. Target
training scoremap for each joint is constructed by assigning a
positive label 1 at each location within $15$ px to the ground truth,
and negative label 0 otherwise.

%% as follows: at each location for each
%% joint a positive label 1 is assigned if the location is within $15$ px
%% to the ground truth, and negative label 0 otherwise. Locations with
%% all 0 are the negatives.

\myparagraph{Location refinement.} In order to improve location
precision we follow \cite{girshickICCV15fastrcnn}: we add a location
refinement FC layer after the FC7 and use the relative offsets
$(\Delta x,\Delta y)$ from a scoremap location to the ground truth as
targets.

%% While scoremaps provide sufficient
%% resolution, location precision can be improved.
%% \cite{Tompson:2015:EOL} train additional net to produce fine
%% scoremaps. We follow an alternative and simpler route
%% \cite{girshickICCV15fastrcnn}: we add a location refinement FC layer
%% after the FC7 and use the relative offsets $(\Delta x,\Delta y)$ from a scoremap
%% location to the ground truth as targets.

\myparagraph{Regression to other parts.} Similar to location
refinement we add an extra term to the objective function where for
each part we regress onto all other part locations. We found this
auxiliary task to improve the performance
(c.f. Sec.~\ref{sec:experiments:unary}).
%% We envision these predictions
%% to improve the spatial model as well and leave this for the future
%% work.

%% While we currently discard
%% these extra predictions, they could be used for constructing more
%% robust pairwise terms in the future work.

\myparagraph{Training.} We follow best practices and use SGD for CNN
training. In each iteration we forward-pass a single image. After FC6 we
select all positive and random negative samples to keep the pos/neg
ratio as 25\%/75\%. We finetune VGG from Imagenet model to pose
estimation task and use training data augmentation. We train for 430k
iterations with the following learning rates (lr): 10k at lr=0.001,
180k at lr=0.002, 120k at lr=0.0002 and 120k at
lr=0.0001. Pre-training at smaller lr prevents the gradients from
diverging.
%% We also randomly scale image within range $[0.85;1.15]$ for data
%% augmentation.

%% In summary, by carefully re-purposing and tuning readily available components we achieve state of the art unary performance without employing highly specialized
%% architectures as in \cite{Tompson:2015:EOL}.

\input{table_rcnn_unary_lsp_small.tex}

\subsection{Evaluation of Part Detectors}
\label{sec:experiments:unary}
%% We now evaluate the proposed part detection models on the task of
%% single person pose estimation thereby significantly outperforming the
%% state of the art.

\myparagraph{Datasets.} We train and evaluate on three public
benchmarks: ``Leeds Sports Poses'' (LSP)~\cite{johnson10bmvc}
(person-centric (PC)),
%including $1000$ training and $1000$
%testing images of people doing sports; 
``LSP Extended'' (LSPET)
~\cite{johnson11cvpr}\footnote{To reduce labeling noise we re-annotated original
  high-resolution images and make the data available at \url{http://datasets.d2.mpi-inf.mpg.de/hr-lspet/hr-lspet.zip}}, and  %consisting of $10000$ training images;
%performing ``acrobatics'' and ``parkour''
``MPII Human Pose'' (``Single Person'')~\cite{andriluka14cvpr}.
%% consisting of $19185$ training and $7247$ testing people in every
%% day activities.
%% As in latter case each image may contain several individuals, rough
%% location and scale information is available at test time.
The MPII training set ($19185$ people) is used as default. In some
cases LSP training \textit{and} LSPET are added to MPII (marked as MPII+LSPET in the
experiments).
%% downloaded the original
%% high-resolution images using the provided Flickr links and

\myparagraph{Evaluation measures.} We use the standard 
``PCK''
%% ``Percentage of
%% Correct Keypoints (PCK)'' 
metric~\cite{sapp13cvpr,Toshev:2014:DHP,tompson14nips} and
%% : the body joint is considered to be correctly localized
%% if it's predicted location falls within a threshold distance
%% w.r.t. the ground truth location.
%% On the LSP dataset, we follow
%% \cite{sapp13cvpr,Toshev:2014:DHP,tompson14nips} and use the threshold
%% distance as $0.2$ of the torso diameter computed between the left
%% shoulder and right hip.
evaluation scripts available on the web page of~\cite{andriluka14cvpr}.
%% and thus are directly comparable to other
%% methods.
%On the MPII dataset we use PCK$_h$ measure defined by the
%evaluation protocol~\cite{andriluka14cvpr}.
%% On the MPII dataset, we use
%% $0.5$ of the head size as a threshold, as defined by the evaluation
%% protocol~\cite{andriluka14cvpr} (PCKh measure).
In addition, %to PCK at fixed threshold, 
we report ``Area under
Curve'' (AUC) computed for the entire range of PCK thresholds.

\myparagraph{$\rcnn$.} Evaluation of~$\rcnn$ on LSP is shown in
Tab.~\ref{tab:unary:rcnn}. Oracle selecting per part the closest
%% to the ground
%% truth out of 
from $2,000$ proposals achieves $97.8$\% PCK, as proposals cover majority
of the ground truth locations. Choosing a single proposal per part
using DPM score achieves $23.0$\% PCK -- not surprising given the
difficulty of the body part detection problem. Re-scoring the
proposals using $\rcnn$ with AlexNet~\cite{krizhevsky12nips}
dramatically improves the performance to $56.9$\% PCK, as CNN learns
richer image representations.
%This is
%achieved using basis scale $1$ ($\approx$ head size) of proposals.
%% and training with initial
%% learning rate (lr) of $0.001$ for $80$k iterations, after which lr was
%% reduced by $0.1$, for a total of $140$k iterations. In addition, we
%% use bounding box regression and default IoU threshold of $0.5$ for
%% pos/neg label assignment~\cite{girshickICCV15fastrcnn}.
Extending the regions by $4$x (1x $\approx$ head size) achieves 65.1\%
PCK, as it incorporates more context including the information about
symmetric parts and allows to implicitly encode higher-order part
relations. % into the part
%%detector.
%% No improvements observed for larger scales.
%% Augmenting the training set by horizontally flipping and jittering
%% training samples, increasing the number of positives by reducing
%% positive IoU threshold to $0.4$.  increasing the lr, lr reduction step
%% and total number of iterations altogether improves the performance to
%% $72.4$\% PCK. We refer to the supplementary material for detailed
%% analysis.
Using data augmentation and slightly tuning training parameters
improves the performance to $72.4$\% PCK. We refer to the
Appendix~\ref{seq:supplemental:lsp} for detailed analysis.
%% All results above are achieved by finetuning the AlexNet
%% architecture from the ImageNet model to the MPII training
%% set. Further finetuning the MPII-finetuned model to the LSP
%% training set increases the performance to $77.9$\% PCK. This is due
%% to the fact that image statistics of more diverse MPII dataset
%% differ from the LSP biased towards a few sport activities. Using
%% the deeper VGG architecture improves over more shallow AlexNet
%% achieving remarkable 82.8\% PCK. Strong increase in AUC (57.0
%% vs. 50\%) characterizes the improvement for smaller PCK evaluation
%% thresholds. Switching off bounding box regression results into
%% performance drop (81.3\% PCK, 53.2\% AUC) thus showing the
%% importance of the bounding box regression for better part
%% localization. Overall $\rcnn$ obtains very good results on LSP
%% dataset by far outperforming the state of the art
%% (c.f. Tab.~\ref{tab:multicut:lsp}, rows $7-9$). Unary-only
%% evaluation on MPII Single Person shows competitive performance
%% (Tab.~\ref{tab:multicut:mpii}, row $1$).
Deeper VGG architecture improves over smaller AlexNet reaching
$77.9$\% PCK. All results so far are achieved by finetuning the
ImageNet models on MPII. Further finetuning to LSP leads to remarkable
82.8\% PCK: CNN learns LSP-specific image representations.
%% image statistics of more diverse MPII dataset differ from
%% LSP biased towards a few sport activities. 
Strong increase in AUC (57.0 vs. 50\%) is due to improvements for
smaller PCK thresholds. Using no bounding box regression leads to
performance drop (81.3\% PCK, 53.2\% AUC): location refinement is
crucial for better localization. Overall $\rcnn$ obtains very good
results on LSP by far outperforming the state of the art
(c.f. Tab.~\ref{tab:multicut:lsp}, rows $7-9$). Evaluation on MPII
shows competitive performance (Tab.~\ref{tab:multicut:mpii}, row $1$).

\input{table_dense_unary_lsp.tex}

\myparagraph{$\dense$.} The results are in Tab.~\ref{tab:unary:dense}.
Training with VGG on MPII with softmax loss achieves $80.8$\% PCK
thereby outperforming $\rcnn$ (c.f. Tab.~\ref{tab:unary:rcnn}, row
6). This shows the advantages of fully convolutional training and
evaluation.
%% of all, we obtain state of the art performance on this
%% dataset by using the simplest version of fully convolutional network
%% trained just on MPII dataset.
Expectedly, training on larger MPII+LSPET dataset improves the results
($83.0$ vs. $80.8$\% PCK). Using cross-entropy loss with sigmoid
activations improves the results to $83.8$\% PCK, as it better models
the appearance of close-by parts. Location refinement improves
localization accuracy ($84.8$\% PCK), which becomes more clear when
analyzing AUC ($61.5$ vs. $55.6$\%). Interestingly, regressing to other
parts further improves PCK to $86.1$\% showing a value of training
with the auxiliary task. Finally, finetuning to LSP achieves the best
result of $87.1$\% PCK, which is significantly higher than the best
published results (c.f. Tab.~\ref{tab:multicut:lsp}, rows
$7-9$). Unary-only evaluation on MPII reveals slightly higher AUC
results compared to the state of the art
(Tab.~\ref{tab:multicut:mpii}, row $3-4$).

\subsection{Using Detections in DeepCut Models}
\label{sec:unary-prob}
The SPLP problem is NP-hard, to solve instances of it efficiently we
select a subset of representative detections from the entire set
produced by a model.
%% In particular, we first perform
%% non-maximum suppression and then for each detection $d$, we take the
%% maximum of all the $p_{dc}$ as its confidence. Detection subset then
%% consists of the top $n$ detections with the highest confidence.
In our experiments we use $|D|= 100$ as default detection set size.
% $|D| = 125$ and $|D|= 150$.
%% In addition, the $x_{dc}$ variables are constrained to $0$ during the
%% optimization, if $p_{dc} \leq 0.2$.
In case of the $\rcnn$ we directly use the softmax output as unary
probabilities: $f_{p_{dc}} = (p_{d1},\ldots,p_{dc})$, where $p_{dc}$
is the probability of the detection $d$ being the part class $c$. For
$\dense$ detection model we use the sigmoid detection unary scores.
