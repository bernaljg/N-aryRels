\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Brown \bgroup et al\mbox.\egroup
  }{1992}]{ngram}
Brown, P.~F.; Desouza, P.~V.; Mercer, R.~L.; Pietra, V. J.~D.; and Lai, J.~C.
\newblock 1992.
\newblock Class-based n-gram models of natural language.
\newblock {\em Computational linguistics} (4):467--479.

\bibitem[\protect\citeauthoryear{Cambria, Olsher, and
  Rajagopal}{2014}]{SenticNet}
Cambria, E.; Olsher, D.; and Rajagopal, D.
\newblock 2014.
\newblock Senticnet 3: {A} common and common-sense knowledge base for
  cognition-driven sentiment analysis.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence},  1515--1521.

\bibitem[\protect\citeauthoryear{Chen \bgroup et al\mbox.\egroup
  }{2015}]{MXNet}
Chen, T.; Li, M.; Li, Y.; Lin, M.; Wang, N.; Wang, M.; Xiao, T.; Xu, B.; Zhang,
  C.; and Zhang, Z.
\newblock 2015.
\newblock Mxnet: {A} flexible and efficient machine learning library for
  heterogeneous distributed systems.
\newblock {\em CoRR} abs/1512.01274.

\bibitem[\protect\citeauthoryear{Chung \bgroup et al\mbox.\egroup }{2014}]{GRU}
Chung, J.; G{\"{u}}l{\c{c}}ehre, {\c{C}}.; Cho, K.; and Bengio, Y.
\newblock 2014.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock {\em CoRR} abs/1412.3555.

\bibitem[\protect\citeauthoryear{Cortes and
  Vapnik}{1995}]{Cortes1995SupportvectorN}
Cortes, C., and Vapnik, V.
\newblock 1995.
\newblock Support-vector networks.
\newblock {\em Machine Learning} 20(3):273--297.

\bibitem[\protect\citeauthoryear{Gong, Luo, and Zhang}{2017}]{diin}
Gong, Y.; Luo, H.; and Zhang, J.
\newblock 2017.
\newblock Natural language inference over interaction space.
\newblock {\em CoRR} abs/1709.04348.

\bibitem[\protect\citeauthoryear{Grave \bgroup et al\mbox.\egroup
  }{2017}]{fasttext}
Grave, E.; Mikolov, T.; Joulin, A.; and Bojanowski, P.
\newblock 2017.
\newblock Bag of tricks for efficient text classification.
\newblock In {\em Proceedings of the European Chapter of the Association for
  Computational Linguistics},  427--431.

\bibitem[\protect\citeauthoryear{Iyyer \bgroup et al\mbox.\egroup }{2015}]{dan}
Iyyer, M.; Manjunatha, V.; Boyd{-}Graber, J.~L.; and III, H.~D.
\newblock 2015.
\newblock Deep unordered composition rivals syntactic methods for text
  classification.
\newblock In {\em Proceedings of the Annual Meeting of the Association for
  Computational Linguistics},  1681--1691.

\bibitem[\protect\citeauthoryear{Kim}{2014}]{TextCNN}
Kim, Y.
\newblock 2014.
\newblock Convolutional neural networks for sentence classification.
\newblock {\em CoRR} abs/1408.5882.

\bibitem[\protect\citeauthoryear{Kingma and Ba}{2014}]{adam}
Kingma, D.~P., and Ba, J.
\newblock 2014.
\newblock Adam: {A} method for stochastic optimization.
\newblock {\em CoRR} abs/1412.6980.

\bibitem[\protect\citeauthoryear{Liu, Qiu, and Huang}{2016}]{TextRNN}
Liu, P.; Qiu, X.; and Huang, X.
\newblock 2016.
\newblock Recurrent neural network for text classification with multi-task
  learning.
\newblock In {\em Proceedings of the International Joint Conference on
  Artificial Intelligence},  2873--2879.

\bibitem[\protect\citeauthoryear{Mikolov \bgroup et al\mbox.\egroup
  }{2013}]{Word2vec}
Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G.~S.; and Dean, J.
\newblock 2013.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em Advances in Neural Information Processing Systems},
  3111--3119.

\bibitem[\protect\citeauthoryear{Munkhdalai and Yu}{2017}]{encoder}
Munkhdalai, T., and Yu, H.
\newblock 2017.
\newblock Neural semantic encoders.
\newblock In {\em Proceedings of the Annual Meeting on Association for
  Computational Linguistics},  397.

\bibitem[\protect\citeauthoryear{Parikh \bgroup et al\mbox.\egroup
  }{2016}]{DATTENTION}
Parikh, A.~P.; T{\"{a}}ckstr{\"{o}}m, O.; Das, D.; and Uszkoreit, J.
\newblock 2016.
\newblock A decomposable attention model for natural language inference.
\newblock In {\em Proceedings of the Conference on Empirical Methods in Natural
  Language Processing},  2249--2255.

\bibitem[\protect\citeauthoryear{Press and Wolf}{2017}]{output}
Press, O., and Wolf, L.
\newblock 2017.
\newblock Using the output embedding to improve language models.
\newblock In {\em Proceedings of the European Chapter of the Association for
  Computational Linguistics},  157--163.

\bibitem[\protect\citeauthoryear{Qiao \bgroup et al\mbox.\egroup
  }{2018}]{regionemb}
Qiao, C.; Huang, B.; Niu, G.; Li, D.; Dong, D.; He, W.; Yu, D.; and Wu, H.
\newblock 2018.
\newblock A new method of region embedding for text classification.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[\protect\citeauthoryear{Schwenk \bgroup et al\mbox.\egroup
  }{2017}]{vdcnn}
Schwenk, H.; Barrault, L.; Conneau, A.; and LeCun, Y.
\newblock 2017.
\newblock Very deep convolutional networks for text classification.
\newblock In {\em Proceedings of the European Chapter of the Association for
  Computational Linguistics},  1107--1116.

\bibitem[\protect\citeauthoryear{Wallach}{2006}]{bow}
Wallach, H.~M.
\newblock 2006.
\newblock Topic modeling: beyond bag-of-words.
\newblock In {\em Proceedings of the International Conference on Machine
  Learning},  977--984.

\bibitem[\protect\citeauthoryear{Wang and Jiang}{2016a}]{Wang2016ACM}
Wang, S., and Jiang, J.
\newblock 2016a.
\newblock A compare-aggregate model for matching text sequences.
\newblock {\em CoRR} abs/1611.01747.

\bibitem[\protect\citeauthoryear{Wang and Jiang}{2016b}]{llstm}
Wang, S., and Jiang, J.
\newblock 2016b.
\newblock Learning natural language inference with {LSTM}.
\newblock In {\em The North American Chapter of the Association for
  Computational Linguistics},  1442--1451.

\bibitem[\protect\citeauthoryear{Wang, Hamza, and Florian}{2017}]{BIMPM}
Wang, Z.; Hamza, W.; and Florian, R.
\newblock 2017.
\newblock Bilateral multi-perspective matching for natural language sentences.
\newblock In {\em Proceedings of the International Joint Conference on
  Artificial Intelligence},  4144--4150.

\bibitem[\protect\citeauthoryear{Wu \bgroup et al\mbox.\egroup }{2017}]{smn}
Wu, Y.; Wu, W.; Xing, C.; Zhou, M.; and Li, Z.
\newblock 2017.
\newblock Sequential matching network: {A} new architecture for multi-turn
  response selection in retrieval-based chatbots.
\newblock In {\em Proceedings of the Annual Meeting on Association for
  Computational Linguistics},  496--505.

\bibitem[\protect\citeauthoryear{Yang \bgroup et al\mbox.\egroup }{2016}]{HAN}
Yang, Z.; Yang, D.; Dyer, C.; He, X.; Smola, A.~J.; and Hovy, E.~H.
\newblock 2016.
\newblock Hierarchical attention networks for document classification.
\newblock In {\em The North American Chapter of the Association for
  Computational Linguistics},  1480--1489.

\bibitem[\protect\citeauthoryear{Yogatama \bgroup et al\mbox.\egroup
  }{2017}]{dlstm}
Yogatama, D.; Dyer, C.; Ling, W.; and Blunsom, P.
\newblock 2017.
\newblock Generative and discriminative text classification with recurrent
  neural networks.
\newblock {\em CoRR} abs/1703.01898.

\bibitem[\protect\citeauthoryear{Yu and Munkhdalai}{2017}]{TREE}
Yu, H., and Munkhdalai, T.
\newblock 2017.
\newblock Neural tree indexers for text understanding.
\newblock In {\em Proceedings of the European Chapter of the Association for
  Computational Linguistics},  11--21.

\bibitem[\protect\citeauthoryear{Zhang, Zhao, and LeCun}{2015}]{charcnn}
Zhang, X.; Zhao, J.~J.; and LeCun, Y.
\newblock 2015.
\newblock Character-level convolutional networks for text classification.
\newblock In {\em Advances in Neural Information Processing Systems},
  649--657.

\bibitem[\protect\citeauthoryear{Zhu and Hastie}{2001}]{LR}
Zhu, J., and Hastie, T.
\newblock 2001.
\newblock Kernel logistic regression and the import vector machine.
\newblock In {\em Advances in Neural Information Processing Systems},
  1081--1088.

\end{thebibliography}
