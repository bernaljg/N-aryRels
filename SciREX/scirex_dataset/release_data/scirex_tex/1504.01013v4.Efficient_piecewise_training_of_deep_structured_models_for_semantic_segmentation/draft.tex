
\documentclass[10pt,twocolumn,letterpaper]{article}


\input{macro.tex}


\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
%

\usepackage{amssymb, eucal}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}

%
\fancyfoot[LE, LO]{\it Published in Proc.\ IEEE Conf.\ Computer Vision and Pattern Recognition (CVPR) 2016. }

\renewcommand{\footrulewidth}{0pt}
\renewcommand{\headrulewidth}{0pt}

%

%
%
%
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\cvprfinalcopy %

\def\cvprPaperID{1140} %
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

%
%
\begin{document}

%

\title{Efficient Piecewise Training of Deep Structured Models  for Semantic Segmentation}

\author{Guosheng Lin, \;  Chunhua Shen, \;
Anton van den Hengel, \; Ian Reid\\
The University of Adelaide; and Australian Centre for Robotic Vision\\
}

\maketitle
%




%
\begin{abstract}
   Recent advances in  semantic image segmentation have mostly been achieved by
  training deep convolutional neural networks (CNNs).
  We show how to improve semantic segmentation through the use of contextual information;
	specifically, we explore `patch-patch' context between image regions, and `patch-background' context.
  For learning from the patch-patch context,
 we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring patches.
  Efficient piecewise training of the proposed deep structured model is then applied to avoid repeated expensive CRF inference
  for back propagation.
   For capturing the patch-background context, we show that a network design
   with traditional multi-scale image input and sliding pyramid pooling is effective for improving performance.
	Our experimental results set new state-of-the-art performance on a number of
    popular semantic segmentation datasets, including NYUDv2, PASCAL VOC 2012, PASCAL-Context, and SIFT-flow.
	In particular, we achieve an intersection-over-union score of $78.0$ on the challenging PASCAL VOC 2012 dataset.
\end{abstract}



\input{intro.tex}
\input{method.tex}
\input{exp.tex}


\section{Conclusions}

We have proposed a method which combines CNNs and CRFs to exploit complex
contextual information for semantic image segmentation.
We formulate CNN based pairwise potentials for modeling
semantic relations between image regions.
Our method shows best performance on several popular datasets including the PASCAL VOC 2012 dataset.
The proposed method is potentially widely applicable to other vision tasks.



\paragraph{Acknowledgments}
This research was supported by the Data to Decisions
Cooperative Research Centre and by the Australian Research Council
through the Australian Centre for Robotic Vision (CE140100016).
C. Shen's participation was supported by  an ARC Future Fellowship (FT120100969).
I. Reid's participation was supported by an ARC Laureate Fellowship (FL130100102).


C. Shen is the corresponding author (e-mail: chunhua.shen@adelaide.edu.au).




{\small
\bibliographystyle{ieee}
\bibliography{CSRef}
}

\end{document}
