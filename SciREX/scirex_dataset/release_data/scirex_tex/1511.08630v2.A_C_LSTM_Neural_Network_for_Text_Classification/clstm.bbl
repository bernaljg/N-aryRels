\begin{thebibliography}{}

\bibitem[\protect\citename{Bastien \bgroup et al.\egroup }2012]{theano}
Fr{\'{e}}d{\'{e}}ric Bastien, Pascal Lamblin, Razvan Pascanu, James Bergstra,
  Ian~J. Goodfellow, Arnaud Bergeron, Nicolas Bouchard, and Yoshua Bengio.
\newblock 2012.
\newblock Theano: new features and speed improvements.
\newblock Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop.

\bibitem[\protect\citename{Cho \bgroup et al.\egroup }2014]{gru}
Kyunghyun Cho, Bart Van~Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock 2014.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock {\em arXiv preprint arXiv:1406.1078}.

\bibitem[\protect\citename{Collobert \bgroup et al.\egroup }2011]{scratch}
Ronan Collobert, Jason Weston, L{\'e}on Bottou, Michael Karlen, Koray
  Kavukcuoglu, and Pavel Kuksa.
\newblock 2011.
\newblock Natural language processing (almost) from scratch.
\newblock {\em The Journal of Machine Learning Research}, 12:2493--2537.

\bibitem[\protect\citename{Denil \bgroup et al.\egroup }2014]{modelling}
Misha Denil, Alban Demiraj, Nal Kalchbrenner, Phil Blunsom, and Nando
  de~Freitas.
\newblock 2014.
\newblock Modelling, visualising and summarising documents with a single
  convolutional neural network.
\newblock {\em arXiv preprint arXiv:1406.3830}.

\bibitem[\protect\citename{Devlin \bgroup et al.\egroup }2014]{smt}
Jacob Devlin, Rabih Zbib, Zhongqiang Huang, Thomas Lamar, Richard Schwartz, and
  John Makhoul.
\newblock 2014.
\newblock Fast and robust neural network joint models for statistical machine
  translation.
\newblock In {\em Proceedings of the 52nd Annual Meeting of the Association for
  Computational Linguistics}, volume~1, pages 1370--1380.

\bibitem[\protect\citename{Hinton \bgroup et al.\egroup }2012]{dropout}
Geoffrey~E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and
  Ruslan~R Salakhutdinov.
\newblock 2012.
\newblock Improving neural networks by preventing co-adaptation of feature
  detectors.
\newblock {\em The Computing Research Repository (CoRR)}.

\bibitem[\protect\citename{Hochreiter and Schmidhuber}1997]{lstm}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock 1997.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780.

\bibitem[\protect\citename{Irsoy and Cardie}2014]{drnn}
Ozan Irsoy and Claire Cardie.
\newblock 2014.
\newblock Deep recursive neural networks for compositionality in language.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2096--2104.

\bibitem[\protect\citename{Johnson and Zhang}2015]{effective}
Rie Johnson and Tong Zhang.
\newblock 2015.
\newblock Effective use of word order for text categorization with
  convolutional neural networks.
\newblock {\em Human Language Technologies: The 2015 Annual Conference of the
  North American Chapter of the ACL}, pages 103--112.

\bibitem[\protect\citename{Kalchbrenner \bgroup et al.\egroup }2014]{dcnn}
Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom.
\newblock 2014.
\newblock A convolutional neural network for modelling sentences.
\newblock {\em Association for Computational Linguistics (ACL)}.

\bibitem[\protect\citename{Kim}2014]{kim}
Yoon Kim.
\newblock 2014.
\newblock Convolutional neural networks for sentence classification.
\newblock In {\em Proceedings of Empirical Methods on Natural Language
  Processing}.

\bibitem[\protect\citename{Le and Mikolov}2014]{pv}
Quoc Le and Tomas Mikolov.
\newblock 2014.
\newblock Distributed representations of sentences and documents.
\newblock In {\em Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pages 1188--1196.

\bibitem[\protect\citename{Lei \bgroup et al.\egroup }2015]{tao}
Tao Lei, Regina Barzilay, and Tommi Jaakkola.
\newblock 2015.
\newblock Molding cnns for text: non-linear, non-consecutive convolutions.
\newblock In {\em Proceedings of Empirical Methods on Natural Language
  Processing}.

\bibitem[\protect\citename{Li and Roth}2002]{trec}
Xin Li and Dan Roth.
\newblock 2002.
\newblock Learning question classifiers.
\newblock In {\em Proceedings of the 19th international conference on
  Computational linguistics-Volume 1}, pages 1--7. Association for
  Computational Linguistics.

\bibitem[\protect\citename{Li \bgroup et al.\egroup }2015]{lijiwei}
Jiwei Li, Dan Jurafsky, and Eudard Hovy.
\newblock 2015.
\newblock When are tree structures necessary for deep learning of
  representations?
\newblock In {\em Proceedings of Empirical Methods on Natural Language
  Processing}.

\bibitem[\protect\citename{Mikolov \bgroup et al.\egroup }2013b]{wordrep}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock 2013b.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em Advances in neural information processing systems}, pages
  3111--3119.

\bibitem[\protect\citename{Mou \bgroup et al.\egroup }2015]{mou}
Lili Mou, Hao Peng, Ge~Li, Yan Xu, Lu~Zhang, and Zhi Jin.
\newblock 2015.
\newblock Discriminative neural sentence modeling by tree-based convolution.
\newblock {\em Unpublished manuscript: http://arxiv. org/abs/1504. 01106v5.
  Version}, 5.

\bibitem[\protect\citename{Nair and Hinton}2010]{relu}
Vinod Nair and Geoffrey~E Hinton.
\newblock 2010.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pages 807--814.

\bibitem[\protect\citename{Pascanu \bgroup et al.\egroup }2014]{evidence}
Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio.
\newblock 2014.
\newblock How to construct deep recurrent neural networks.
\newblock In {\em Proceedings of the conference on International Conference on
  Learning Representations (ICLR)}.

\bibitem[\protect\citename{Sainath \bgroup et al.\egroup }2015]{saina}
Tara~N Sainath, Oriol Vinyals, Andrew Senior, and Hasim Sak.
\newblock 2015.
\newblock Convolutional, long short-term memory, fully connected deep neural
  networks.
\newblock {\em IEEE International Conference on Acoustics, Speech and Signal
  Processing}.

\bibitem[\protect\citename{Silva \bgroup et al.\egroup }2011]{svmtrec}
Joao Silva, Lu{\'\i}sa Coheur, Ana~Cristina Mendes, and Andreas Wichert.
\newblock 2011.
\newblock From symbolic to sub-symbolic information in question classification.
\newblock {\em Artificial Intelligence Review}, 35(2):137--154.

\bibitem[\protect\citename{Socher \bgroup et al.\egroup }2012]{mvrnn}
Richard Socher, Brody Huval, Christopher~D Manning, and Andrew~Y Ng.
\newblock 2012.
\newblock Semantic compositionality through recursive matrix-vector spaces.
\newblock In {\em Proceedings of Empirical Methods on Natural Language
  Processing}, pages 1201--1211.

\bibitem[\protect\citename{Socher \bgroup et al.\egroup }2013a]{parsing}
Richard Socher, John Bauer, Christopher~D Manning, and Andrew~Y Ng.
\newblock 2013a.
\newblock Parsing with compositional vector grammars.
\newblock In {\em In Proceedings of the ACL conference}. Citeseer.

\bibitem[\protect\citename{Socher \bgroup et al.\egroup }2013b]{socher2013}
Richard Socher, Alex Perelygin, Jean~Y Wu, Jason Chuang, Christopher~D Manning,
  Andrew~Y Ng, and Christopher Potts.
\newblock 2013b.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In {\em Proceedings of Empirical Methods on Natural Language
  Processing}, volume 1631, page 1642. Citeseer.

\bibitem[\protect\citename{Sutskever \bgroup et al.\egroup }2014]{seq}
Ilya Sutskever, Oriol Vinyals, and Quoc~VV Le.
\newblock 2014.
\newblock Sequence to sequence learning with neural networks.
\newblock In {\em Advances in neural information processing systems}, pages
  3104--3112.

\bibitem[\protect\citename{Tai \bgroup et al.\egroup }2015]{tai2015}
Kai~Sheng Tai, Richard Socher, and Christopher~D Manning.
\newblock 2015.
\newblock Improved semantic representations from tree-structured long
  short-term memory networks.
\newblock {\em Association for Computational Linguistics (ACL)}.

\bibitem[\protect\citename{Tang \bgroup et al.\egroup }2015]{tang}
Duyu Tang, Bing Qin, and Ting Liu.
\newblock 2015.
\newblock Document modeling with gated recurrent neural network for sentiment
  classification.
\newblock In {\em Proceedings of Empirical Methods on Natural Language
  Processing}.

\bibitem[\protect\citename{Tieleman and Hinton}2012]{rmsprop}
T.~Tieleman and G~Hinton.
\newblock 2012.
\newblock Lecture 6.5 - rmsprop, coursera: Neural networks for machine
  learning.

\bibitem[\protect\citename{Xu \bgroup et al.\egroup }2015]{caption}
Kelvin Xu, Jimmy Ba, Ryan Kiros, Aaron Courville, Ruslan Salakhutdinov, Richard
  Zemel, and Yoshua Bengio.
\newblock 2015.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock In {\em Proceedings of 2015th International Conference on Machine
  Learning}.

\bibitem[\protect\citename{Zhao \bgroup et al.\egroup }2015]{zhao}
Han Zhao, Zhengdong Lu, and Pascal Poupart.
\newblock 2015.
\newblock Self-adaptive hierarchical sentence model.
\newblock In {\em Proceedings of International Joint Conferences on Artificial
  Intelligence}.

\end{thebibliography}
