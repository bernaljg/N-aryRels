\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, and de~Freitas]{andrychowicz2016learning}
Andrychowicz, Marcin, Denil, Misha, Gomez, Sergio, Hoffman, Matthew~W, Pfau,
  David, Schaul, Tom, and de~Freitas, Nando.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock \emph{arXiv preprint arXiv:1606.04474}, 2016.

\bibitem[Barbour \& Chen(2005)Barbour and Chen]{barbour2005introduction}
Barbour, Andrew~D and Chen, Louis Hsiao~Yun.
\newblock \emph{An introduction to {Stein's} method}, volume~4.
\newblock World Scientific, 2005.

\bibitem[Briol et~al.(2015)Briol, Oates, Girolami, Osborne, Sejdinovic,
  et~al.]{briol2015probabilistic}
Briol, Fran{\c{c}}ois-Xavier, Oates, Chris, Girolami, Mark, Osborne, Michael~A,
  Sejdinovic, Dino, et~al.
\newblock Probabilistic integration: A role for statisticians in numerical
  analysis?
\newblock \emph{arXiv preprint http://arxiv.org/abs/1512.00933}, 2015.

\bibitem[Chwialkowski et~al.(2016)Chwialkowski, Strathmann, and
  Gretton]{chwialkowski2016kernel}
Chwialkowski, Kacper, Strathmann, Heiko, and Gretton, Arthur.
\newblock A kernel test of goodness of fit.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2016.

\bibitem[Daniel et~al.(2016)Daniel, Taylor, and Nowozin]{daniel2016learning}
Daniel, Christian, Taylor, Jonathan, and Nowozin, Sebastian.
\newblock Learning step size controllers for robust neural network training.
\newblock In \emph{Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem[Delyon \& Portier(2014)Delyon and Portier]{delyon2014integral}
Delyon, Bernard and Portier, Fran{\c{c}}ois.
\newblock Integral approximation by kernel smoothing.
\newblock \emph{arXiv preprint arXiv:1409.0733}, 2014.

\bibitem[Dziugaite et~al.(2015)Dziugaite, Roy, and
  Ghahramani]{dziugaite2015training}
Dziugaite, Gintare~Karolina, Roy, Daniel~M., and Ghahramani, Zoubin.
\newblock Training generative neural networks via maximum mean discrepancy
  optimization.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence (UAI)},
  2015.

\bibitem[Gershman \& Goodman(2014)Gershman and Goodman]{gershman2014amortized}
Gershman, Samuel~J and Goodman, Noah~D.
\newblock Amortized inference in probabilistic reasoning.
\newblock In \emph{Proceedings of the 36th Annual Conference of the Cognitive
  Science Society}, 2014.

\bibitem[Geyer(1991)]{geyer1991markov}
Geyer, Charles~J.
\newblock {Markov} chain {Monte} {Carlo} maximum likelihood.
\newblock In \emph{Computing Science and Statistics: Proc. 23rd Symp.
  Interface}, pp.\  156--163, 1991.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley,
  David, Ozair, Sherjil, Courville, Aaron, and Bengio, Yoshua.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2672--2680, 2014.

\bibitem[Gorham \& Mackey(2015)Gorham and Mackey]{gorham2015measuring}
Gorham, Jack and Mackey, Lester.
\newblock Measuring sample quality with {Stein's} method.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  226--234, 2015.

\bibitem[Henmi et~al.(2007)Henmi, Yoshida, and Eguchi]{henmi2007importance}
Henmi, Masayuki, Yoshida, Ryo, and Eguchi, Shinto.
\newblock Importance sampling via the estimated sampler.
\newblock \emph{Biometrika}, 94\penalty0 (4):\penalty0 985--991, 2007.

\bibitem[Hinton(2002)]{hinton2002training}
Hinton, Geoffrey~E.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural computation}, 14\penalty0 (8):\penalty0 1771--1800,
  2002.

\bibitem[Kim \& Bengio(2016)Kim and Bengio]{kim2016deep}
Kim, Taesup and Bengio, Yoshua.
\newblock Deep directed generative models with energy-based probability
  estimation.
\newblock \emph{arXiv preprint arXiv:1606.03439}, 2016.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, Diederik and Ba, Jimmy.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, Diederik~P and Welling, Max.
\newblock Auto-encoding variational {Bayes}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2013.

\bibitem[Li \& Malik(2016)Li and Malik]{li2016learning}
Li, Ke and Malik, Jitendra.
\newblock Learning to optimize.
\newblock \emph{arXiv preprint arXiv:1606.01885}, 2016.

\bibitem[Li et~al.(2015)Li, Swersky, and Zemel]{li2015generative}
Li, Yujia, Swersky, Kevin, and Zemel, Rich.
\newblock Generative moment matching networks.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2015.

\bibitem[Liu \& Lee(2016)Liu and Lee]{liu2016black}
Liu, Qiang and Lee, Jason~D.
\newblock Black-box importance sampling.
\newblock \emph{https://arxiv.org/abs/1610.05247}, 2016.

\bibitem[Liu \& Wang(2016)Liu and Wang]{liu2016stein}
Liu, Qiang and Wang, Dilin.
\newblock Stein variational gradient descent: A general purpose bayesian
  inference algorithm.
\newblock \emph{arXiv preprint arXiv:1608.04471}, 2016.

\bibitem[Liu et~al.(2016)Liu, Lee, and Jordan]{liu2016kernelized}
Liu, Qiang, Lee, Jason~D, and Jordan, Michael~I.
\newblock A kernelized {Stein} discrepancy for goodness-of-fit tests.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2016.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Liu, Ziwei, Luo, Ping, Wang, Xiaogang, and Tang, Xiaoou.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, 2015.

\bibitem[Ngiam et~al.(2011)Ngiam, Chen, Koh, and Ng]{ngiam2011learning}
Ngiam, Jiquan, Chen, Zhenghao, Koh, Pang~W, and Ng, Andrew~Y.
\newblock Learning deep energy models.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, pp.\  1105--1112, 2011.

\bibitem[Nowozin et~al.(2016)Nowozin, Cseke, and Tomioka]{nowozin2016f}
Nowozin, Sebastian, Cseke, Botond, and Tomioka, Ryota.
\newblock f-gan: Training generative neural samplers using variational
  divergence minimization.
\newblock \emph{arXiv preprint arXiv:1606.00709}, 2016.

\bibitem[Oates et~al.(2014)Oates, Girolami, and Chopin]{oates2014control}
Oates, Chris~J, Girolami, Mark, and Chopin, Nicolas.
\newblock {Control functionals for Monte Carlo integration}.
\newblock \emph{Journal of the Royal Statistical Society, Series B}, 2014.

\bibitem[O'Hagan(1987)]{o1987monte}
O'Hagan, Anthony.
\newblock {Monte Carlo} is fundamentally unsound.
\newblock \emph{Journal of the Royal Statistical Society. Series D (The
  Statistician)}, 36\penalty0 (2/3):\penalty0 247--249, 1987.

\bibitem[O'Hagan(1991)]{o1991bayes}
O'Hagan, Anthony.
\newblock Bayes--hermite quadrature.
\newblock \emph{Journal of statistical planning and inference}, 29\penalty0
  (3):\penalty0 245--260, 1991.

\bibitem[Paige \& Wood(2016)Paige and Wood]{paige2016inference}
Paige, Brooks and Wood, Frank.
\newblock Inference networks for sequential monte carlo in graphical models.
\newblock \emph{arXiv preprint arXiv:1602.06701}, 2016.

\bibitem[Radford et~al.(2015)Radford, Metz, and
  Chintala]{radford2015unsupervised}
Radford, Alec, Metz, Luke, and Chintala, Soumith.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1511.06434}, 2015.

\bibitem[Ranganath et~al.(2016)Ranganath, Altosaar, Tran, and Blei]{operator}
Ranganath, R., Altosaar, J., Tran, D., and Blei, D.M.
\newblock Operator variational inference.
\newblock 2016.

\bibitem[Ranganath et~al.(2014)Ranganath, Gerrish, and
  Blei]{ranganath2013black}
Ranganath, Rajesh, Gerrish, Sean, and Blei, David~M.
\newblock Black box variational inference.
\newblock In \emph{Proceedings of the International Conference on Artificial
  Intelligence and Statistics (AISTATS)}, 2014.

\bibitem[Ranganath et~al.(2015)Ranganath, Tran, and
  Blei]{ranganath2015hierarchical}
Ranganath, Rajesh, Tran, Dustin, and Blei, David~M.
\newblock Hierarchical variational models.
\newblock \emph{arXiv preprint arXiv:1511.02386}, 2015.

\bibitem[Rezende \& Mohamed(2015{\natexlab{a}})Rezende and
  Mohamed]{jimenez2015variational}
Rezende, Danilo~Jimenez and Mohamed, Shakir.
\newblock Variational inference with normalizing flows.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2015{\natexlab{a}}.

\bibitem[Rezende \& Mohamed(2015{\natexlab{b}})Rezende and
  Mohamed]{rezende2015variational}
Rezende, Danilo~Jimenez and Mohamed, Shakir.
\newblock Variational inference with normalizing flows.
\newblock \emph{arXiv preprint arXiv:1505.05770}, 2015{\natexlab{b}}.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{salimans2016improved}
Salimans, Tim, Goodfellow, Ian, Zaremba, Wojciech, Cheung, Vicki, Radford,
  Alec, and Chen, Xi.
\newblock Improved techniques for training gans.
\newblock \emph{arXiv preprint arXiv:1606.03498}, 2016.

\bibitem[Stein(1972)]{stein1972}
Stein, Charles.
\newblock A bound for the error in the normal approximation to the distribution
  of a sum of dependent random variables.
\newblock In \emph{Proceedings of the Sixth Berkeley Symposium on Mathematical
  Statistics and Probability, Volume 2: Probability Theory}, pp.\  583--602,
  1972.

\bibitem[Tieleman(2008)]{tieleman2008training}
Tieleman, Tijmen.
\newblock Training restricted boltzmann machines using approximations to the
  likelihood gradient.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pp.\  1064--1071. ACM, 2008.

\bibitem[Tran et~al.(2015)Tran, Ranganath, and Blei]{tran2015variational}
Tran, Dustin, Ranganath, Rajesh, and Blei, David~M.
\newblock Variational gaussian process.
\newblock \emph{arXiv preprint arXiv:1511.06499}, 2015.

\bibitem[Xie et~al.(2016)Xie, Lu, Zhu, and Wu]{xie2016theory}
Xie, Jianwen, Lu, Yang, Zhu, Song-Chun, and Wu, Ying~Nian.
\newblock A theory of generative convnet.
\newblock \emph{arXiv preprint arXiv:1602.03264}, 2016.

\bibitem[Yu et~al.(2015)Yu, Seff, Zhang, Song, Funkhouser, and
  Xiao]{yu2015lsun}
Yu, Fisher, Seff, Ari, Zhang, Yinda, Song, Shuran, Funkhouser, Thomas, and
  Xiao, Jianxiong.
\newblock Lsun: Construction of a large-scale image dataset using deep learning
  with humans in the loop.
\newblock \emph{arXiv preprint arXiv:1506.03365}, 2015.

\bibitem[Zhao et~al.(2016)Zhao, Mathieu, and LeCun]{zhao2016energy}
Zhao, Junbo, Mathieu, Michael, and LeCun, Yann.
\newblock Energy-based generative adversarial network.
\newblock \emph{arXiv preprint arXiv:1609.03126}, 2016.

\end{thebibliography}
