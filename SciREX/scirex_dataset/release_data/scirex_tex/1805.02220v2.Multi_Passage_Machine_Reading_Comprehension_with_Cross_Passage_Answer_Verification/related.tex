\section{Related Work}
\label{related}

%\subsection{Single-document Reading Comprehension}
% single model
% 1. modeling MRC on single passage modeling and treats the multi-passage as a single one and ignores the redundant information
% 2. moreover, boundary detection mechanism on single passage tend to detect segmentation symbols, like '\$', '.' etc. (will be discuss in Section 5), which makes the cross-passage verification 

Machine reading comprehension made rapid progress in recent years, especially for single-passage MRC task, such as SQuAD \cite{squad}. Mainstream studies \cite{bidaf, match-lstm, dcn} treat reading comprehension as extracting answer span from the given passage, which is usually achieved by predicting the start and end position of the answer.  We implement our boundary model similarly by employing the boundary-based pointer network \cite{match-lstm}. Another inspiring work is from \newcite{rnet}, where the authors  propose to match the passage against itself so that the representation can aggregate evidence from the whole passage. Our verification model adopts a similar idea. However, we collect information across passages and our attention is based on the answer representation, which is much more efficient than attention over all passages. For the model training, \newcite{dcn+} argues that  the boundary loss encourages exact answers at the cost of penalizing overlapping answers. Therefore they propose a mixed objective that incorporates rewards derived from word overlap. Our joint training approach has a similar function. By taking the content and verification loss into consideration, our model will give less loss for overlapping answers than those unmatched answers, and our loss function is totally differentiable. 


%Based on single passage assumption, MRC models \cite{match-lstm, bidaf, memen, aoa, rnet} treat multi-passages as a single concatenated one and neglect the fact of passages are independent written, between which cross-passage information is exploitable. Moreover, the boundary detection mechanism tends to detect segmentation symbols, like '\$', '.' etc. (discussed in Section 4), it may play a minor role in multi-passages verification and the concrete content is much more valuable. While in our model, we introduce a content model to capture question-aware passage semantic and further exploit it by cross-passage verification.

%\subsection{Multi-document Reading Comprehension}
% multi document
% 1. part of 

Recently, we also see emerging interests in multi-passage MRC from both the academic \cite{searchqa, triviaqa} and industrial community \cite{marco, dureader}. Early studies \cite{reasonet, rnet} usually concat those passages and employ the same models designed for single-passage MRC. However, more and more latest studies start to design specific methods that can read multiple passages more effectively. In the aspect of passage selection, \newcite{r3} introduced a pipelined approach that rank the passages first and then read the selected passages for answering questions. \newcite{snet}  treats the passage ranking as an auxiliary task that can be trained jointly with the reading comprehension model. Actually, the target of our answer verification is very similar to that of the passage selection, while we pay more attention to the answer content and the answer verification process. Speaking of the answer verification, \newcite{evidence_aggregation} has a similar motivation to ours. They attempt to aggregate the evidence from different passages and choose the final answer from n-best candidates. However, they implement their idea as a separate reranking step after reading comprehension, while our answer verification is a component of the whole model that can be trained end-to-end. 

 
%Realizing various challenges exist in multi-passage reading comprehension, many efforts have been devoted to narrow the gap between single and multi passage reading. In the aspect of passage selecting, \cite{r3} introduced a passage ranker and read relevant passages instead of reading all of them, \cite{multi-para} utilized a calibrated confidence to evaluate independent reading results of different passages, and further \cite{snet} jointly modeled passage selecting and passage reading in a single model.  Such kind of models choose to neglect information between multi-passages. In the aspect of multi-passage information utilizing, \cite{evidence_aggregation} adopted a reranker to select the most supportive answer from nbest candidates. And our method tries to exploit information between multi-passages by an end-to-end model which may jointly boost both single\&multi-passage reading sides instead of modeling them separately.
