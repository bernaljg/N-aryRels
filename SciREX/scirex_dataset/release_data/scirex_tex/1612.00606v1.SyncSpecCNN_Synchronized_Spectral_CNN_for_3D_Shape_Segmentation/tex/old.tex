According to \cite{ovsjanikov2012functional}, functional map could be used to align spectral domain of different shapes but some rough correspondence among shapes in the spatial domain is needed for its computation. Therefore, a friendly input representation for SpecTN should be able to encode rough spatial correspondences. In addition, since functional map is used to synchronize different spectral domains, we need to provide knowledge about these spectral domains to SpecTN. To feed a representation encoding rough correspondences to SpecTN, we first use the hierarchical joint alignment algorithm described in \cite{shapenet2015} to align all the input shapes into a canonical 3D space, where rough correspondences among different shapes could be obtained by simple nearest neighbor search. Then we voxelize input shapes and use voxel cells to indicate correspondence among different shapes, namely two vertices are in correspondence if they fall into the same voxel cell. In this way, we could get rid of cumbersome pairwise correspondences computation. This voxelized representation of jointly aligned input shapes provides rough correspondences, thus very friendy for functional map prediction. To add knowledge about different spectral domains in the input, we convert eigenbases $\myvec{B}=\{\myvec{b_i}\}$ of each $\graph$, which are represented as vertex functions, into voxel functions $\myvec{B_v}=\{\myvec{b_{vi}}\}$. And the shape voxel representation together with voxel functions $\myvec{B_v}$ will serve as the input to SpecTN.

Converting graph vertex function into voxel function is pretty straightforward in our setting and we simply need to transport the vertex function value to corresponding voxel cells where the vertex lies in. If multiple vertex function values are transported into a same voxel cell, average pooling will be done to get the voxel function value. If no vertex function value is transported into a voxel cell, $\myvec{0}$ will be assigned to it.


The second challenge in our design is about optimizing SpecTN. High dimensional spectral transformation estimation is harder in nature compared with low dimensional spatial transformation. To facilitate learning, we adopt two approaches: using a good initialization and adding regularizations. To be specific, we pre-train the SpecTN in a supervised fashion so that it predicts functional map to roughly canonicalize different spectral domains, then we fine-tune SpecTN while training the whole SyncSpecCNN with an end task such as shape segmentation. Regularizations are used during training to force the output $C$ of SpecTN to be close to an orthogonal map, namely we add $||CC^T-I||_F^2$ into the overall loss function. The pre-training step is crucial since it provides a good initialization for fine-tuning. To obtain rough functional map for pre-training, we first construct an average shape graph $\bar{\graph}_v$ in the voxelized 3D space where we have jointly aligned the input shapes. Then we estimate functional maps to align each individual spectral domain, approximated by $\myvec{B_v}$, with the average spectral domain, depicted by $\bar{\myvec{B}}_v$. Here $\bar{\myvec{B}}_v$ denotes the eigenbases corresponding to the graph Laplacian of $\bar{\graph}_v$. The average shape graph $\bar{\graph}_v$ lies in the voxelized 3D space, with a vertex set $\vertex_v$ including all the voxel cells and an edge set $\edge_v$ describing connections among voxel cells. $\bar{\graph}_v$ is obtained by simply associating every vertex in each $\graph$ with some voxel cell and adding every edge weight in each $\graph$ onto some connection weight between voxels. \todo{show visualization for laplacian eigenvectors of the average graph}. We use voxel functions $\myvec{B_v}$ instead of $\myvec{B}$ to approximate the spectral domain of each individual $\graph$ since they are defined on the same voxelized 3D space as $\bar{\myvec{B}}_v$ and the functional map $C_v$ aligning $\myvec{B_v}$ with $\bar{\myvec{B}}_v$ could be computed through simple matrix multiplication $C_v=\bar{\myvec{B}}_v^T\bar{\myvec{B}}_v$. The computed functional map will serve as supervision and SpecTN is pre-trained to minimize the loss function $||C-C_v||_F^2$.

The resolution of the voxelized 3D space does not need to be high since we are only focusing on synchronizing low-frequency end of different spectral domains. We use a small volumetric CNN \cite{qi2016volumetric} for our SpecTN and there is an regression layer in the end of SpecTN to predict the functional map.