\BOOKMARK [1][-]{appendix.A}{Experiments on MNIST}{}% 1
\BOOKMARK [2][-]{subsection.A.1}{Details for dropout training}{appendix.A}% 2
\BOOKMARK [2][-]{subsection.A.2}{Details for dropout finetuning}{appendix.A}% 3
\BOOKMARK [2][-]{subsection.A.3}{Effect on features}{appendix.A}% 4
\BOOKMARK [1][-]{appendix.B}{Experiments on TIMIT}{}% 5
\BOOKMARK [2][-]{subsection.B.1}{Pretraining}{appendix.B}% 6
\BOOKMARK [2][-]{subsection.B.2}{Dropout Finetuning}{appendix.B}% 7
\BOOKMARK [1][-]{appendix.C}{Experiments on Reuters}{}% 8
\BOOKMARK [1][-]{appendix.D}{Tiny Images and CIFAR-10}{}% 9
\BOOKMARK [1][-]{appendix.E}{ImageNet}{}% 10
\BOOKMARK [1][-]{appendix.F}{Convolutional Neural Networks}{}% 11
\BOOKMARK [2][-]{subsection.F.1}{Pooling}{appendix.F}% 12
\BOOKMARK [2][-]{subsection.F.2}{Local response normalization}{appendix.F}% 13
\BOOKMARK [2][-]{subsection.F.3}{Neuron nonlinearities}{appendix.F}% 14
\BOOKMARK [2][-]{subsection.F.4}{Objective function}{appendix.F}% 15
\BOOKMARK [2][-]{subsection.F.5}{Weight initialization}{appendix.F}% 16
\BOOKMARK [2][-]{subsection.F.6}{Training}{appendix.F}% 17
\BOOKMARK [2][-]{subsection.F.7}{Learning rates}{appendix.F}% 18
\BOOKMARK [1][-]{appendix.G}{Models for CIFAR-10}{}% 19
\BOOKMARK [1][-]{appendix.H}{Models for ImageNet}{}% 20
