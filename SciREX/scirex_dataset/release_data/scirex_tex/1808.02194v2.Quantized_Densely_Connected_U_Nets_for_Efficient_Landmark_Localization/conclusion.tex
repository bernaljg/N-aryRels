\section{Conclusion}
We have generalized the dense connectivity into the stacked U-Nets, resulting in a novel, simple and effective DU-Net. It connects blocks with the same semantic meanings in different U-Nets. $Order$-$K$ connectivity is proposed to improve its parameter efficiency. An iterative refinement is also introduced make it more parameter efficient. It could halve a DU-Net but achieves comparable accuracy.
%G%
Through network quantization, the training memory consumption and model size can further be reduced simultaneously.
%G%
 Experiments show the DU-Net could achieve state-of-the-art performances as other landmark localizers but with only  $\sim$30\% parameters, $\sim$2\% model size and $\sim$25\% training memory.