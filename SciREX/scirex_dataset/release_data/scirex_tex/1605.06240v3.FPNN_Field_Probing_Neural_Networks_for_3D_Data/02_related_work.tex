\section{Related Work}
\label{sec:related_work}

\vspace{-0.2cm}

\paragraph{3D Shape Descriptors.} 3D shape descriptors lie at the core of shape analysis and a large variety of shape descriptors have been designed in the past few decades. 3D shapes can be converted into 2D images and represented by descriptors of the converted images~\cite{Johnson_TPAMI99_Using,Chen_CGF03_On}. 3D shapes can also be represented by their inherent statistical properties, such as distance distribution~\cite{Osada_ToG02_Shape} and spherical harmonic decomposition~\cite{Kazhdan_SGP03_Rotation}. Heat kernel signatures extract shape descriptions by simulating an heat diffusion process on 3D shapes~\cite{Sun_SGP09_A,Bronstein_ToG11_Shape}. In contrast, we propose an approach for learning the shape descriptor extraction scheme, rather than hand-crafting it.

\vspace{-0.1cm}

\paragraph{Convolutional Neural Networks.} The architecture of CNN~\cite{Lecun_IEEE98_Gradient} is designed to take advantage of the 2D structure of an input image (or other 2D input such as a speech signal), and CNNs have advanced the performance records in most image understanding tasks in computer vision~\cite{Russakovsky_IJCV15_ImageNet}. An important reason for this success is that by leveraging large image datasets (e.g., ImageNet~\cite{Deng_CVPR09_ImageNet}), general purpose image descriptors can be directly learned from data, which adapt to the data better and outperform hand-crafted features~\cite{LeCun_Nature15_Deep}. Our approach follows this paradigm of feature learning, but is specifically designed for 3D data coming from object surface representations.

\paragraph{CNNs on Depth and 3D Data.} With rapid advances in 3D sensing technology, depth has became available as an additional information channel beyond color. Such 2.5D data can be represented as multiple channel images, and processed by 2D CNNs~\cite{Socher_NIPS12_Convolutional,Gupta_ECCV14_Learning,Eitel_IROS15_Multimodal}. Wu et al.~\cite{WU_CVPR15_3D} in a pioneering paper proposed to extend 2D CNNs to process 3D data directly (3D ShapeNets).
%They represent view-based 2.5D data as 3D binary voxel grid, which is the input to a CNN with 3D convolutional filters.
A similar approach (VoxNet) was proposed in~\cite{Maturana_IROS15_VoxNet}. However, such approaches cannot work on high resolution 3D data, as the computational complexity is a cubic function of the voxel grid resolution. Since CNNs for images have been extensively studied, 3D shapes can be rendered into 2D images, and be represented by the CNN features of the images~\cite{Shi_SPL15_DeepPano,Su_ICCV15_Multi}, which, surprisingly, outperforms any 3D CNN approaches, in a 3D shape classification task. Recently, Qi et al.~\cite{qi2016volumetric} presented an extensive study of these volumetric and multi-view CNNs and refreshed the performance records. In this work, we propose a feature learning approach that is specifically designed to take advantage of the sparsity of 3D data, and compare against results reported in~\cite{qi2016volumetric}. Note that our method was designed without explicit consideration of deformable objects, which is a purely extrinsic construction. While 3D data is represented as meshes, neural networks can benefit from intrinsic constructions\cite{litman2014learning,masci2015geodesic,Boscaini_SGP15_Learning,boscaini2016anisotropic} to learn object invariance to isometries, thus require less training data for handling deformable objects.

Our method can be viewed as an efficient scheme of sparse coding\cite{donoho2006compressed}. The learned weights of each probing curve can be interpreted as the entries of the coding matrix in the sparse coding framework. Compared with conventional sparse coding, our framework is not only computationally more tractable, but also enables an end-to-end learning system.