\section{Conclusion}
We proposed a novel and powerful network, V2V-PoseNet, for 3D hand and human pose estimation from a single depth map. To overcome the drawbacks of previous works, we converted 2D depth map into the 3D voxel representation and processed it using our 3D CNN model. Also, instead of directly regressing 3D coordinates of keypoints, we estimated the per-voxel likelihood for each keypoint. Those two conversions boost the performance significantly and make the proposed V2V-PoseNet outperform previous works on the three 3D hand and one 3D human pose estimation datasets by a large margin. It also allows us to win the 3D hand pose estimation challenge. As \emph{voxel-to-voxel} prediction is firstly tried in 3D hand and human pose estimation from a single depth map, we hope this work to provide a new way of accurate 3D pose estimation.