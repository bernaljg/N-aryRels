%
% File emnlp2016.tex
%

\documentclass[11pt,letterpaper]{article}
\usepackage{emnlp2016}
\usepackage{times}
\usepackage{latexsym}


\usepackage{color}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{natbib}
\usepackage{xspace}

\usepackage{array}
\newcolumntype{L}{>{\arraybackslash}m{10cm}}

\newcommand{\mcb}[1]{\multicolumn{2}{c|}{#1}}
\newcommand{\mc}[1]{\multicolumn{2}{c}{#1}}
\newcommand{\WikiMovies}{{\sc WikiMovies}\xspace}
\definecolor{dgreen}{rgb}{0.0,0.4,0.0}
\definecolor{dred}{rgb}{1,0.0,0.0}
\usepackage{amsmath}
\usepackage{amssymb}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\softmax}{softmax}


% Uncomment this line for the final submission:
\emnlpfinalcopy

%  Enter the EMNLP Paper ID here:
\def\emnlppaperid{679}

% To expand the titlebox for more authors, uncomment
% below and set accordingly.
% \addtolength\titlebox{.5in}

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Key-Value Memory Networks for Directly Reading Documents}

% Author information can be set in various styles:
% For several authors from the same institution:
 \author{
Alexander H. Miller$^{1}$ \mbox{~~}
Adam Fisch$^{1}$ \mbox{~~}
Jesse Dodge$^{1,2}$ \mbox{~~}
Amir-Hossein Karimi$^{1}$ \\
{\bf Antoine Bordes$^{1}$} \mbox{~~}
{\bf Jason Weston$^{1}$} \\
$^{1}$Facebook AI Research, 770 Broadway, New York, NY, USA\\
$^{2}$Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA\\
{\tt \{ahm,afisch,jessedodge,ahkarimi,abordes,jase\}@fb.com}
 }

% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}
% If the title and author information does not fit in the area allocated,
% place \setlength\titlebox{<new height>} right after
% at the top, where <new height> can be something larger than 2.25in
%\author{Siddharth Patwardhan \and Daniele Pighin\\
%  {\tt publication@emnlp2016.net}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
Directly reading documents and being able to answer questions from them is an unsolved challenge.
To avoid its inherent difficulty, question answering (QA) has been directed towards
using Knowledge Bases (KBs) instead,
which has proven effective.
Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers,
and too sparse, e.g. Wikipedia contains much more information than Freebase.
In this work we introduce a new method, Key-Value Memory Networks,
that makes reading documents more viable
by utilizing different encodings in the addressing  and output stages of the memory read operation.
To compare using  KBs, information extraction or Wikipedia documents directly in a single
framework we construct
 an analysis tool, {\sc WikiMovies}, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies.
Our method reduces the gap between all three settings.
It also achieves state-of-the-art results on the existing {\sc WikiQA} benchmark.
\end{abstract}

\section{Introduction}
\vspace{-0.5ex}
\input{intro}

%\vspace{-0.25ex}
\section{Related Work}
\vspace{-0.5ex}
\input{rwork}

%\vspace{-0.5ex}
\section{Key-Value Memory Networks} \label{sec:models}
\vspace{-0.5ex}
\input{models}

%\vspace{-1ex}
\section{The WikiMovies Benchmark} \label{sec:data}
\vspace{-0.5ex}
The \WikiMovies ~benchmark consists of question-answer pairs in the domain of movies.
It was built with the following goals in mind:
(i) machine learning techniques should have ample training examples for learning;
and (ii) one can analyze easily the performance of different representations of knowledge and break
down the results by question type.
%
The dataset can be downloaded from \url{http://fb.ai/babi}.

\input{data}

%\vspace{-0.5ex}
\section{Experiments}\label{sec:exp}
\vspace{-0.5ex}
\input{exps}

%\vspace{-0.5ex}
\section{Conclusion}
\vspace{-0.5ex}
\input{conc}


\bibliography{dialog}
\bibliographystyle{natbib}

\end{document}
