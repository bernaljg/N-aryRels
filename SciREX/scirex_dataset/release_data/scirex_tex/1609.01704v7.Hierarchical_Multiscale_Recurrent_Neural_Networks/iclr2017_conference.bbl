\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bahdanau et~al.(2016)Bahdanau, Chorowski, Serdyuk, Bengio,
  et~al.]{bahdanau2016end}
Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Yoshua Bengio, et~al.
\newblock End-to-end attention-based large vocabulary speech recognition.
\newblock In \emph{2016 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  4945--4949. IEEE, 2016.

\bibitem[Bengio(2009)]{bengio2009learning}
Yoshua Bengio.
\newblock Learning deep architectures for ai.
\newblock \emph{Foundations and trends{\textregistered} in Machine Learning},
  2\penalty0 (1):\penalty0 1--127, 2009.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Chan et~al.(2016)Chan, Jaitly, Le, and Vinyals]{chan2016listen}
William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals.
\newblock Listen, attend and spell: A neural network for large vocabulary
  conversational speech recognition.
\newblock In \emph{2016 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  4960--4964. IEEE, 2016.

\bibitem[Cho et~al.(2014)Cho, van Merrienboer, Gulcehre, Bougares, Schwenk, and
  Bengio]{Cho-et-al-EMNLP2014}
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger
  Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using {RNN} encoder-decoder for
  statistical machine translation.
\newblock In \emph{Proceedings of the Empiricial Methods in Natural Language
  Processing (EMNLP 2014)}, October 2014.

\bibitem[Chung et~al.(2015)Chung, Gulcehre, Cho, and Bengio]{chung2015gated}
Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio.
\newblock Gated feedback recurrent neural networks.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML)}, 2015.

\bibitem[Chung et~al.(2016)Chung, Cho, and Bengio]{chung2016character}
Junyoung Chung, Kyunghyun Cho, and Yoshua Bengio.
\newblock A character-level decoder without explicit segmentation for neural
  machine translation.
\newblock \emph{Association for Computational Linguistics (ACL)}, 2016.

\bibitem[Cooijmans et~al.(2016)Cooijmans, Ballas, Laurent, and
  Courville]{cooijmans2016recurrent}
Tim Cooijmans, Nicolas Ballas, C{\'e}sar Laurent, and Aaron Courville.
\newblock Recurrent batch normalization.
\newblock \emph{arXiv preprint arXiv:1603.09025}, 2016.

\bibitem[Courbariaux et~al.(2016)Courbariaux, Hubara, Soudry, El-Yaniv, and
  Bengio]{courbariaux2016binarized}
Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua
  Bengio.
\newblock Binarized neural networks: Training deep neural networks with weights
  and activations constrained to+ 1 or-1.
\newblock \emph{arXiv preprint arXiv:1602.02830}, 2016.

\bibitem[El~Hihi \& Bengio(1995)El~Hihi and Bengio]{el1995hierarchical}
Salah El~Hihi and Yoshua Bengio.
\newblock Hierarchical recurrent neural networks for long-term dependencies.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  493--499. Citeseer, 1995.

\bibitem[Fern{\'a}ndez et~al.(2007)Fern{\'a}ndez, Graves, and
  Schmidhuber]{fernandez2007sequence}
Santiago Fern{\'a}ndez, Alex Graves, and J{\"u}rgen Schmidhuber.
\newblock Sequence labelling in structured domains with hierarchical recurrent
  neural networks.
\newblock In \emph{Proceedings of the 20th international joint conference on
  Artifical intelligence}, pp.\  774--779. Morgan Kaufmann Publishers Inc.,
  2007.

\bibitem[Graves(2013)]{graves2013generating}
Alex Graves.
\newblock Generating sequences with recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1308.0850}, 2013.

\bibitem[Ha et~al.(2016)Ha, Dai, and Le]{ha2016hypernetworks}
David Ha, Andrew Dai, and Quoc~V Le.
\newblock Hypernetworks.
\newblock \emph{arXiv preprint arXiv:1609.09106}, 2016.

\bibitem[Hinton(2012)]{hinton2012coursera}
G.~Hinton.
\newblock Neural networks for machine learning.
\newblock Coursera, video lectures, 2012.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hoffman et~al.(2013)Hoffman, Tzeng, Donahue, Jia, Saenko, and
  Darrell]{hoffman2013one}
Judy Hoffman, Eric Tzeng, Jeff Donahue, Yangqing Jia, Kate Saenko, and Trevor
  Darrell.
\newblock One-shot adaptation of supervised deep convolutional models.
\newblock \emph{arXiv preprint arXiv:1312.6204}, 2013.

\bibitem[Huang et~al.(2016)Huang, Sun, Liu, Sedra, and
  Weinberger]{huang2016deep}
Gao Huang, Yu~Sun, Zhuang Liu, Daniel Sedra, and Kilian Weinberger.
\newblock Deep networks with stochastic depth.
\newblock \emph{arXiv preprint arXiv:1603.09382}, 2016.

\bibitem[Hutter(2012)]{Hutter2012}
Marcus Hutter.
\newblock The human knowledge compression contest.
\newblock 2012.
\newblock URL \url{http://prize.hutter1.net/}.

\bibitem[Kalchbrenner et~al.(2015)Kalchbrenner, Danihelka, and
  Graves]{kalchbrenner2015grid}
Nal Kalchbrenner, Ivo Danihelka, and Alex Graves.
\newblock Grid long short-term memory.
\newblock \emph{arXiv preprint arXiv:1507.01526}, 2015.

\bibitem[Kim(2014)]{kim2014convolutional}
Yoon Kim.
\newblock Convolutional neural networks for sentence classification.
\newblock \emph{arXiv preprint arXiv:1408.5882}, 2014.

\bibitem[Kim et~al.(2015)Kim, Jernite, Sontag, and Rush]{kim2015character}
Yoon Kim, Yacine Jernite, David Sontag, and Alexander~M Rush.
\newblock Character-aware neural language models.
\newblock \emph{arXiv preprint arXiv:1508.06615}, 2015.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kong et~al.(2015)Kong, Dyer, and Smith]{kong2015segmental}
Lingpeng Kong, Chris Dyer, and Noah~A Smith.
\newblock Segmental recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1511.06018}, 2015.

\bibitem[Koutn{\'\i}k et~al.(2014)Koutn{\'\i}k, Greff, Gomez, and
  Schmidhuber]{koutnik2014clockwork}
Jan Koutn{\'\i}k, Klaus Greff, Faustino Gomez, and J{\"u}rgen Schmidhuber.
\newblock A clockwork rnn.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning (ICML 2014)}, 2014.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1097--1105, 2012.

\bibitem[Krueger \& Memisevic(2015)Krueger and
  Memisevic]{krueger2015regularizing}
David Krueger and Roland Memisevic.
\newblock Regularizing rnns by stabilizing activations.
\newblock \emph{arXiv preprint arXiv:1511.08400}, 2015.

\bibitem[Krueger et~al.(2016)Krueger, Maharaj, Kram{\'a}r, Pezeshki, Ballas,
  Ke, Goyal, Bengio, Larochelle, Courville, et~al.]{krueger2016zoneout}
David Krueger, Tegan Maharaj, J{\'a}nos Kram{\'a}r, Mohammad Pezeshki, Nicolas
  Ballas, Nan~Rosemary Ke, Anirudh Goyal, Yoshua Bengio, Hugo Larochelle, Aaron
  Courville, et~al.
\newblock Zoneout: Regularizing rnns by randomly preserving hidden activations.
\newblock \emph{arXiv preprint arXiv:1606.01305}, 2016.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{lecun2015deep}
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
\newblock Deep learning.
\newblock \emph{Nature}, 521\penalty0 (7553):\penalty0 436--444, 2015.

\bibitem[Lin et~al.(1996)Lin, Horne, Tino, and Giles]{lin1996learning}
Tsungnan Lin, Bill~G Horne, Peter Tino, and C~Lee Giles.
\newblock Learning long-term dependencies in narx recurrent neural networks.
\newblock \emph{IEEE Transactions on Neural Networks}, 7\penalty0 (6):\penalty0
  1329--1338, 1996.

\bibitem[Ling et~al.(2015)Ling, Trancoso, Dyer, and Black]{ling2015character}
Wang Ling, Isabel Trancoso, Chris Dyer, and Alan~W Black.
\newblock Character-based neural machine translation.
\newblock \emph{arXiv preprint arXiv:1511.04586}, 2015.

\bibitem[Liwicki \& Bunke(2005)Liwicki and Bunke]{liwicki2005iam}
Marcus Liwicki and Horst Bunke.
\newblock Iam-ondb-an on-line english sentence database acquired from
  handwritten text on a whiteboard.
\newblock In \emph{Eighth International Conference on Document Analysis and
  Recognition (ICDAR'05)}, pp.\  956--961. IEEE, 2005.

\bibitem[Mahoney(2005)]{mahoney2005adaptive}
Matthew~V Mahoney.
\newblock Adaptive weighing of context models for lossless data compression.
\newblock 2005.

\bibitem[Mahoney(2009)]{mahoney2009large}
Matthew~V Mahoney.
\newblock Large text compression benchmark.
\newblock \emph{URL: http://www. mattmahoney. net/text/text. html}, 2009.

\bibitem[Marcus et~al.(1993)Marcus, Marcinkiewicz, and
  Santorini]{marcus1993building}
Mitchell~P Marcus, Mary~Ann Marcinkiewicz, and Beatrice Santorini.
\newblock Building a large annotated corpus of english: The penn treebank.
\newblock \emph{Computational linguistics}, 19\penalty0 (2):\penalty0 313--330,
  1993.

\bibitem[Mikolov et~al.(2010)Mikolov, Karafi{\'a}t, Burget, Cernock{\`y}, and
  Khudanpur]{mikolov2010recurrent}
Tomas Mikolov, Martin Karafi{\'a}t, Lukas Burget, Jan Cernock{\`y}, and Sanjeev
  Khudanpur.
\newblock Recurrent neural network based language model.
\newblock In \emph{INTERSPEECH}, volume~2, pp.\ ~3, 2010.

\bibitem[Mikolov et~al.(2012)Mikolov, Sutskever, Deoras, Le, Kombrink, and
  Cernocky]{mikolov2012subword}
Tomas Mikolov, Ilya Sutskever, Anoop Deoras, Hai-Son Le, Stefan Kombrink, and
  J~Cernocky.
\newblock Subword language modeling with neural networks.
\newblock \emph{Preprint}, 2012.
\newblock URL \url{http://www.fit.vutbr.cz/~imikolov/rnnlm/char.pdf}.

\bibitem[Mnih \& Gregor(2014)Mnih and Gregor]{mnih2014neural}
Andriy Mnih and Karol Gregor.
\newblock Neural variational inference and learning in belief networks.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pp.\  1791--1799, 2014.

\bibitem[Mozer(1993)]{mozer1993induction}
Michael~C Mozer.
\newblock Induction of multiscale temporal structure.
\newblock \emph{Advances in neural information processing systems}, pp.\
  275--275, 1993.

\bibitem[Nair \& Hinton(2010)Nair and Hinton]{nair2010rectified}
Vinod Nair and Geoffrey~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pp.\  807--814, 2010.

\bibitem[Pachitariu \& Sahani(2013)Pachitariu and
  Sahani]{pachitariu2013regularization}
Marius Pachitariu and Maneesh Sahani.
\newblock Regularization and nonlinearities for neural language models: when
  are they needed?
\newblock \emph{arXiv preprint arXiv:1301.5650}, 2013.

\bibitem[Pascanu et~al.(2012)Pascanu, Mikolov, and
  Bengio]{pascanu2012difficulty}
Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio.
\newblock On the difficulty of training recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1211.5063}, 2012.

\bibitem[Rocki(2016{\natexlab{a}})]{rocki2016recurrent}
Kamil~M Rocki.
\newblock Recurrent memory array structures.
\newblock \emph{arXiv preprint arXiv:1607.03085}, 2016{\natexlab{a}}.

\bibitem[Rocki(2016{\natexlab{b}})]{rocki2016surprisal}
Kamil~M Rocki.
\newblock Surprisal-driven feedback in recurrent networks.
\newblock \emph{arXiv preprint arXiv:1608.06027}, 2016{\natexlab{b}}.

\bibitem[Schmidhuber(1991)]{schmidhuber1991neural}
J{\"u}rgen Schmidhuber.
\newblock Neural sequence chunkers.
\newblock 1991.

\bibitem[Schmidhuber(1992)]{schmidhuber1992learning}
J{\"u}rgen Schmidhuber.
\newblock Learning complex, extended sequences using the principle of history
  compression.
\newblock \emph{Neural Computation}, 4\penalty0 (2):\penalty0 234--242, 1992.

\bibitem[Schmidhuber(2015)]{schmidhuber2015deep}
J{\"u}rgen Schmidhuber.
\newblock Deep learning in neural networks: An overview.
\newblock \emph{Neural Networks}, 61:\penalty0 85--117, 2015.

\bibitem[Sordoni et~al.(2015)Sordoni, Bengio, Vahabi, Lioma, Grue~Simonsen, and
  Nie]{sordoni2015hierarchical}
Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob
  Grue~Simonsen, and Jian-Yun Nie.
\newblock A hierarchical recurrent encoder-decoder for generative context-aware
  query suggestion.
\newblock In \emph{Proceedings of the 24th ACM International on Conference on
  Information and Knowledge Management}, pp.\  553--562. ACM, 2015.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Nitish Srivastava, Geoffrey~E Hinton, Alex Krizhevsky, Ilya Sutskever, and
  Ruslan Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Sutskever et~al.(2011)Sutskever, Martens, and
  Hinton]{sutskever2011generating}
Ilya Sutskever, James Martens, and Geoffrey~E Hinton.
\newblock Generating text with recurrent neural networks.
\newblock In \emph{Proceedings of the 28th International Conference on Machine
  Learning (ICML'11)}, pp.\  1017--1024, 2011.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3104--3112, 2014.

\bibitem[Team et~al.(2016)Team, Al-Rfou, Alain, Almahairi, Angermueller,
  Bahdanau, Ballas, Bastien, Bayer, Belikov, et~al.]{team2016theano}
The Theano~Development Team, Rami Al-Rfou, Guillaume Alain, Amjad Almahairi,
  Christof Angermueller, Dzmitry Bahdanau, Nicolas Ballas, Fr{\'e}d{\'e}ric
  Bastien, Justin Bayer, Anatoly Belikov, et~al.
\newblock Theano: A python framework for fast computation of mathematical
  expressions.
\newblock \emph{arXiv preprint arXiv:1605.02688}, 2016.

\bibitem[Vezhnevets et~al.(2016)Vezhnevets, Mnih, Agapiou, Osindero, Graves,
  Vinyals, Kavukcuoglu, et~al.]{vezhnevets2016strategic}
Alexander Vezhnevets, Volodymyr Mnih, John Agapiou, Simon Osindero, Alex
  Graves, Oriol Vinyals, Koray Kavukcuoglu, et~al.
\newblock Strategic attentive writer for learning macro-actions.
\newblock \emph{arXiv preprint arXiv:1606.04695}, 2016.

\bibitem[Vinyals et~al.(2015)Vinyals, Toshev, Bengio, and
  Erhan]{vinyals2015show}
Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan.
\newblock Show and tell: A neural image caption generator.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3156--3164, 2015.

\bibitem[Williams(1992)]{williams1992simple}
Ronald~J Williams.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 229--256, 1992.

\bibitem[Wu et~al.(2016)Wu, Zhang, Zhang, Bengio, and
  Salakhutdinov]{wu2016multiplicative}
Yuhuai Wu, Saizheng Zhang, Ying Zhang, Yoshua Bengio, and Ruslan Salakhutdinov.
\newblock On multiplicative integration with recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1606.06630}, 2016.

\bibitem[Zhang et~al.(2016)Zhang, Wu, Che, Lin, Memisevic, Salakhutdinov, and
  Bengio]{zhang2016architectural}
Saizheng Zhang, Yuhuai Wu, Tong Che, Zhouhan Lin, Roland Memisevic, Ruslan
  Salakhutdinov, and Yoshua Bengio.
\newblock Architectural complexity measures of recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1602.08210}, 2016.

\bibitem[Zilly et~al.(2016)Zilly, Srivastava, Koutn{\'\i}k, and
  Schmidhuber]{zilly2016recurrent}
Julian~Georg Zilly, Rupesh~Kumar Srivastava, Jan Koutn{\'\i}k, and J{\"u}rgen
  Schmidhuber.
\newblock Recurrent highway networks.
\newblock \emph{arXiv preprint arXiv:1607.03474}, 2016.

\end{thebibliography}
