\section{Related Work}
In recent years, significant gains have been made in the field of object detection. These recent successes build upon the powerful deep features~\cite{alex} learned from the task of ImageNet classification \cite{imagenet}. R-CNN \cite{rcnn} and OverFeat \cite{overfeat} object detection systems led this wave with impressive results on PASCAL VOC \cite{voc}; and in recent years, more computationally efficient versions have emerged that can efficiently train on larger datasets such as COCO~\cite{coco}. For example, Fast-RCNN~\cite{frcn} shares the convolutions across different region proposals to provide speed-up, Faster-RCNN ~\cite{renNIPS15fasterrcnn} and R-FCN~\cite{dai16rfcn} incorporate region proposal generation in the framework leading to a completely end-to-end version. Building on the sliding-window paradigm of the Overfeat detector, other computationally-efficient approaches have emerged such as YOLO~\cite{yolo16}, SSD~\cite{ssd16} and DenseBox~\cite{densebox}. Thorough comparisons among these methods are discussed in~\cite{Jonathan16}. 


Recent research has focused on three principal directions on developing better object detection systems.
The first direction relies on changing the base architecture of these networks. The central idea is that using deeper networks should not only lead to improvements in classification~\cite{imagenet} but also object detection~\cite{voc,coco}. Some recent work in this direction include ResNet~\cite{resnet},  Inception-ResNet~\cite{inceptionresnet} and ResNetXt~\cite{Xie2016} for object detection.

The second area of research has been to use contextual reasoning, proxy tasks for reasoning and other top-down mechanisms for improving representations for object detection~\cite{ion,DeepMask,TDM17,FPN17,shrivastava16,Gidaris15,Zengeccv16}. For example,~\cite{shrivastava16} use segmentation as a way to contextually prime object detectors and provide feedback to initial layers. ~\cite{ion} uses skip-network architecture and uses features from multiple layers of representation in conjunction with contextual reasoning. Other approaches include using a top-down features for incorporating context and finer details~\cite{DeepMask,TDM17,FPN17} which leads to improved detections.

The third direction to improve a detection systems is to better exploit the data itself. It is often argued that the recent success of object detectors is a product of better visual representation and the availability of large-scale data for learning. Therefore, this third class of approaches try to explore how to better utilize data for improving the performance. One example is to incorporate hard example mining in an effective and efficient setup for training region-based ConvNets~\cite{shrivastavaOHEM}. Other examples of findind hard examples for training include ~\cite{simo2014fracking,wang2015unsupervised,loshchilov2015online}.

Our work follows this third direction of research where the focus is on leveraging data in a better manner. However, instead of trying to sift through the data to find hard examples, we try to generate examples which will be hard for Fast-RCNN to detect/classify. We restrict the space of new positive generation to adding occlusions and deformations to the current existing examples from the dataset. Specifically, we learn adversarial networks which try to predict occlusions and deformations that would lead to mis-classification by Fast-RCNN. Our work is therefore related to lot of recent work in adversarial learning~\cite{goodfellow2014generative,Denton15,Alec15,Mirza15,MathieuCL15,improvedGAN,pathakCVPR16context,CatGAN15,pix2pix2016}. 
For example, techniques have been proposed to improve adversarial learning for image generation~\cite{Alec15} as well as for training better image generative model~\cite{improvedGAN}.
\cite{improvedGAN} also highlights that the adversarial learning can improve image classification in a semi-supervised setting. However, the experiments in these works are conducted on data which has less complexity than object detection datasets, where image generation results are significantly inferior. Our work is also related to a recent work on adversarial training in robotics~\cite{pinto16}. However, instead of using an adversary for better supervision, we use the adversary to generate the hard examples.

