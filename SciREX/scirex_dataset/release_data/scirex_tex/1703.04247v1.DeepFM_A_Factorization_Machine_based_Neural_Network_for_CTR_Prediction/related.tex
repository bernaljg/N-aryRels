\section{Related Work}\label{section:related}

In this paper, a new deep neural network is proposed for CTR prediction. The most related domains are CTR prediction and deep learning in recommender system. In this section, we discuss related work in these two domains.

CTR prediction plays an important role in recommender system~\cite{CTR07,ffm,FTRL}. Besides generalized linear models and FM, a few other models are proposed for CTR prediction, such as tree-based model~\cite{facebookgbdt}, tensor based model~\cite{PITFRendleS10}, support vector machine~\cite{Poly2SVM10}, and bayesian model~\cite{bayesCTR10}.



%Among these models, generalized linear models such as \cite{CTR07,FTRL} are widely used in industry applications because of their simplicity and scalability, however, they are hard to capture high-order feature interactions automatically. For the purpose of capturing order-2 feature interactions automatically, factorization machine approaches such as \cite{fm,ffm} are deployed in real application. Moreover, another non-linear tree-based model~\cite{facebookgbdt} is used for capture non-linear features.

The other related domain is deep learning in recommender systems. In Section~\ref{section:intro} and Section~\ref{section:App:rela}, several deep learning models for CTR prediction are already mentioned, thus we do not discuss about them here. Several deep learning models are proposed in recommendation tasks other than CTR prediction (e.g., \cite{youtube,other-2,other-7,other-6,other-5,wsdm17recurentRS,jointdeepforreviewZhengNY17}). \cite{other-2,other-3,other-4} propose to improve Collaborative Filtering via deep learning. The authors of \cite{other-1,other-7} extract content feature by deep learning to improve the performance of music recommendation. \cite{cnn_image} devises a deep learning network to consider both image feature and basic feature of display adverting. \cite{youtube} develops a two-stage deep learning framework for YouTube video recommendation.



%In recommendation systems, besides CTR predictions, . In this section, we focus mainly on research works studying \emph{deep learning for CTR prediction}, and we categorize these works into four research directions: \emph{feature representation}, \emph{feature interaction}, \emph{network framework} and \emph{data dependencies}.
%
%To get a more precise \emph{feature representation}, \cite{fnn} proposes Factorization-machine supported Neural Network (FNN), which initializes the parameters in the embedding layer with FM model. However, the initializing with FM model is time-consuming, therefore it is not feasible to do that in many real-world industry applications. Moreover, addition operation in FNN may not be able to fully explore the feature interactions.
%
%\emph{Feature interaction} is studied in~\cite{pnn,cnn}, by introducing a cross-product layer between embedding layer and fully-connected layer in the model named PNN, to conduct pairwise feature interaction between any two features. Due to the network structure, In~\cite{cnn}, the authors adapt convolutional neural network (CNN) to extract local-global key feature interactions to improve the prediction. These two models have their own drawbacks. \cite{pnn} considers only the high-order transformation on the pairwise feature interaction, but ignores the low-order transformation, which are also important in the CTR prediction. \cite{cnn} focuses on exploring the interactions between neighbor features, however, the interactions between non-neighbor features cannot be captured which limits the performance of the proposed model.
%
%In the aspect of \emph{network framework}, \cite{wide-n-deep} proposes a hybrid network structure combining a linear model and a deep model in order to take into account both memorization and generalization to make CTR predictions. The limitation of this model is that expertise feature engineering efforts are still needed in the ``wide part" of their proposed model. \cite{cnn_image} also proposes a hybrid network structure to handle different domains of features for display advertising when images information is available. In their framework, image features are processed by a sub convolutional neural network while basic features are fed into a regular sub fully-connected neural network, and lastly these two sub networks are joint by several fully-connected layers. However, this model is hard to generalize to the case when there is no image information.
%
%A recurrent neural network (RNN) structure is proposed in~\cite{rnn} to capture the \emph{data dependency} in users' click log data. However, sequential dependency in click data can be modeled only when there is a long period of data available which limits the applicable scenarios.
