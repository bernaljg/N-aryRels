\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{BartunovV18}
S.~Bartunov and D.~P. Vetrov.
\newblock Few-shot generative modelling with generative matching networks.
\newblock In {\em AISTATS}, 2018.

\bibitem{Bengio92}
S.~Bengio, Y.~Bengio, J.~Cloutier, and J.~Gecsei.
\newblock On the optimization of a synaptic learning rule.
\newblock In {\em Optimality in Artificial and Biological Neural Networks},
  pages 6--8. Univ. of Texas, 1992.

\bibitem{BengioLCW09}
Y.~Bengio, J.~Louradour, R.~Collobert, and J.~Weston.
\newblock Curriculum learning.
\newblock In {\em ICML}, 2009.

\bibitem{CanevetF16}
O.~Can{\'{e}}vet and F.~Fleuret.
\newblock Large scale hard sample mining with monte carlo tree search.
\newblock In {\em CVPR}, 2016.

\bibitem{ChenPAMI18}
L.~Chen, G.~Papandreou, I.~Kokkinos, K.~Murphy, and A.~L. Yuille.
\newblock Deeplab: Semantic image segmentation with deep convolutional nets,
  atrous convolution, and fully connected crfs.
\newblock {\em {IEEE} Trans. Pattern Anal. Mach. Intell.}, 40(4):834--848,
  2018.

\bibitem{ClevertUH15}
D.~Clevert, T.~Unterthiner, and S.~Hochreiter.
\newblock Fast and accurate deep network learning by exponential linear units
  (elus).
\newblock In {\em ICLR}, 2016.

\bibitem{DalalT05}
N.~Dalal and B.~Triggs.
\newblock Histograms of oriented gradients for human detection.
\newblock In {\em CVPR}, 2005.

\bibitem{Erhan10}
D.~Erhan, Y.~Bengio, A.~C. Courville, P.~Manzagol, P.~Vincent, and S.~Bengio.
\newblock Why does unsupervised pre-training help deep learning?
\newblock {\em Journal of Machine Learning Research}, 11:625--660, 2010.

\bibitem{FinnAL17}
C.~Finn, P.~Abbeel, and S.~Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em ICML}, 2017.

\bibitem{FinnNIPS2018}
C.~Finn, K.~Xu, and S.~Levine.
\newblock Probabilistic model-agnostic meta-learning.
\newblock In {\em NeurIPS}, 2018.

\bibitem{FranceschiICML18}
L.~Franceschi, P.~Frasconi, S.~Salzo, R.~Grazzi, and M.~Pontil.
\newblock Bilevel programming for hyperparameter optimization and
  meta-learning.
\newblock In {\em ICML}, 2018.

\bibitem{Hinton1987}
H.~E. Geoffrey and P.~C. David.
\newblock Using fast weights to deblur old memories.
\newblock In {\em CogSci}, 1987.

\bibitem{GrantICLR2018}
E.~Grant, C.~Finn, S.~Levine, T.~Darrell, and T.~L. Griffiths.
\newblock Recasting gradient-based meta-learning as hierarchical bayes.
\newblock In {\em ICLR}, 2018.

\bibitem{GravesICML2017}
A.~Graves, M.~G. Bellemare, J.~Menick, R.~Munos, and K.~Kavukcuoglu.
\newblock Automated curriculum learning for neural networks.
\newblock In {\em ICML}, 2017.

\bibitem{HarwoodGCRD17}
B.~Harwood, V.~Kumar, G.~Carneiro, I.~Reid, and T.~Drummond.
\newblock Smart mining for deep metric learning.
\newblock In {\em ICCV}, 2017.

\bibitem{He_MaskRCNN17}
K.~He, G.~Gkioxari, P.~Doll{\'{a}}r, and R.~B. Girshick.
\newblock Mask {R-CNN}.
\newblock In {\em ICCV}, 2017.

\bibitem{HeZRS16}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{HuangCVPR017}
J.~Huang, V.~Rathod, C.~Sun, M.~Zhu, A.~Korattikara, A.~Fathi, I.~Fischer,
  Z.~Wojna, Y.~Song, S.~Guadarrama, and K.~Murphy.
\newblock Speed/accuracy trade-offs for modern convolutional object detectors.
\newblock In {\em CVPR}, 2017.

\bibitem{IoffeICML15}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em ICML}, 2015.

\bibitem{Keshari18}
R.~Keshari, M.~Vatsa, R.~Singh, and A.~Noore.
\newblock Learning structure and strength of {CNN} filters for small sample
  size training.
\newblock In {\em CVPR}, 2018.

\bibitem{KhorevaBIBS17}
A.~Khoreva, R.~Benenson, E.~Ilg, T.~Brox, and B.~Schiele.
\newblock Lucid data dreaming for object tracking.
\newblock {\em arXiv}, 1703.09554, 2017.

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv}, 1412.6980, 2014.

\bibitem{CIFAR100}
A.~Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em University of Toronto}, 2009.

\bibitem{LeeICML18}
Y.~Lee and S.~Choi.
\newblock Gradient-based meta-learning with learned layerwise metric and
  subspace.
\newblock In {\em ICML}, 2018.

\bibitem{FeiFeiFP06}
F.~Li, R.~Fergus, and P.~Perona.
\newblock One-shot learning of object categories.
\newblock {\em {IEEE} Trans. Pattern Anal. Mach. Intell.}, 28(4):594--611,
  2006.

\bibitem{LiICML2018}
Z.~Li, F.~Zhou, F.~Chen, and H.~Li.
\newblock Meta-sgd: Learning to learn quickly for few shot learning.
\newblock In {\em ICML}, 2018.

\bibitem{LopezPazNIPS17}
D.~Lopez{-}Paz and M.~Ranzato.
\newblock Gradient episodic memory for continual learning.
\newblock In {\em NIPS}, 2017.

\bibitem{McCloskey1989}
M.~McCloskey and N.~J. Cohen.
\newblock Catastrophic interference in connectionist networks: The sequential
  learning problem.
\newblock In {\em Psychology of learning and motivation}, pages 3--17, 1989.

\bibitem{Mehrotra2017}
A.~Mehrotra and A.~Dukkipati.
\newblock Generative adversarial residual pairwise networks for one shot
  learning.
\newblock {\em arXiv}, 1703.08033, 2017.

\bibitem{MishraICLR2018}
N.~Mishra, M.~Rohaninejad, X.~Chen, and P.~Abbeel.
\newblock Snail: A simple neural attentive meta-learner.
\newblock In {\em ICLR}, 2018.

\bibitem{MunkhdalaiICML2017}
T.~Munkhdalai and H.~Yu.
\newblock Meta networks.
\newblock In {\em ICML}, 2017.

\bibitem{MunkhdalaiICML18}
T.~Munkhdalai, X.~Yuan, S.~Mehri, and A.~Trischler.
\newblock Rapid adaptation with conditionally shifted neurons.
\newblock In {\em ICML}, 2018.

\bibitem{Naik92}
D.~K. Naik and R.~Mammone.
\newblock Meta-neural networks that learn by learning.
\newblock In {\em IJCNN}, 1992.

\bibitem{OreshkinNIPS18}
B.~N. Oreshkin, P.~Rodr{\'{\i}}guez, and A.~Lacoste.
\newblock {TADAM:} task dependent adaptive metric for improved few-shot
  learning.
\newblock In {\em NeurIPS}, 2018.

\bibitem{PanTKY11}
S.~J. Pan, I.~W. Tsang, J.~T. Kwok, and Q.~Yang.
\newblock Domain adaptation via transfer component analysis.
\newblock {\em {IEEE} Trans. Neural Networks}, 22(2):199--210, 2011.

\bibitem{PentinaCVPR15}
A.~Pentina, V.~Sharmanska, and C.~H. Lampert.
\newblock Curriculum learning of multiple tasks.
\newblock In {\em CVPR}, 2015.

\bibitem{FiLM2018}
E.~Perez, F.~Strub, H.~de~Vries, V.~Dumoulin, and A.~C. Courville.
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock In {\em AAAI}, 2018.

\bibitem{QiaoCVPR2018}
S.~Qiao, C.~Liu, W.~Shen, and A.~L. Yuille.
\newblock Few-shot image recognition by predicting parameters from activations.
\newblock In {\em CVPR}, 2018.

\bibitem{RaviICLR2017}
S.~Ravi and H.~Larochelle.
\newblock Optimization as a model for few-shot learning.
\newblock In {\em ICLR}, 2017.

\bibitem{Russakovsky2015}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, A.~C. Berg, and L.~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock {\em International Journal of Computer Vision}, 115(3):211--252,
  2015.

\bibitem{Rusu2019}
A.~A. Rusu, D.~Rao, J.~Sygnowski, O.~Vinyals, R.~Pascanu, S.~Osindero, and
  R.~Hadsell.
\newblock Meta-learning with latent embedding optimization.
\newblock In {\em ICLR}, 2019.

\bibitem{SantoroBBWL16}
A.~Santoro, S.~Bartunov, M.~Botvinick, D.~Wierstra, and T.~P. Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In {\em ICML}, 2016.

\bibitem{SarafianosGNK17}
N.~Sarafianos, T.~Giannakopoulos, C.~Nikou, and I.~A. Kakadiaris.
\newblock Curriculum learning for multi-task classification of visual
  attributes.
\newblock In {\em ICCV Workshops}, 2017.

\bibitem{SchwartzNIPS18}
E.~Schwartz, L.~Karlinsky, J.~Shtok, S.~Harary, M.~Marder, R.~S. Feris,
  A.~Kumar, R.~Giryes, and A.~M. Bronstein.
\newblock Delta-encoder: an effective sample synthesis method for few-shot
  object recognition.
\newblock In {\em NeurIPS}, 2018.

\bibitem{ScottNIPS2018}
T.~R. Scott, K.~Ridgeway, and M.~C. Mozer.
\newblock Adapted deep embeddings: {A} synthesis of methods for k-shot
  inductive transfer learning.
\newblock In {\em NeurIPS}, 2018.

\bibitem{ShelhamerLD17}
E.~Shelhamer, J.~Long, and T.~Darrell.
\newblock Fully convolutional networks for semantic segmentation.
\newblock {\em {IEEE} Trans. Pattern Anal. Mach. Intell.}, 39(4):640--651,
  2017.

\bibitem{ShrivastavaGG16}
A.~Shrivastava, A.~Gupta, and R.~B. Girshick.
\newblock Training region-based object detectors with online hard example
  mining.
\newblock In {\em CVPR}, 2016.

\bibitem{SnellSZ17}
J.~Snell, K.~Swersky, and R.~S. Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock In {\em NIPS}, 2017.

\bibitem{Sun_2018_CVPR}
Q.~Sun, L.~Ma, S.~Joon~Oh, L.~Van~Gool, B.~Schiele, and M.~Fritz.
\newblock Natural and effective obfuscation by head inpainting.
\newblock In {\em CVPR}, 2018.

\bibitem{Sun_2017_CVPR}
Q.~Sun, B.~Schiele, and M.~Fritz.
\newblock A domain based approach to social relation recognition.
\newblock In {\em CVPR}, 2017.

\bibitem{SungCVPR2018}
F.~Sung, Y.~Yang, L.~Zhang, T.~Xiang, P.~H.~S. Torr, and T.~M. Hospedales.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In {\em CVPR}, 2018.

\bibitem{Thrun1998}
S.~Thrun and L.~Pratt.
\newblock Learning to learn: Introduction and overview.
\newblock In {\em Learning to learn}, pages 3--17. Springer, 1998.

\bibitem{VinyalsBLKW16}
O.~Vinyals, C.~Blundell, T.~Lillicrap, K.~Kavukcuoglu, and D.~Wierstra.
\newblock Matching networks for one shot learning.
\newblock In {\em NIPS}, 2016.

\bibitem{WangCVPR2018}
Y.~Wang, R.~B. Girshick, M.~Hebert, and B.~Hariharan.
\newblock Low-shot learning from imaginary data.
\newblock In {\em CVPR}, 2018.

\bibitem{WeiICML2018}
Y.~Wei, Y.~Zhang, J.~Huang, and Q.~Yang.
\newblock Transfer learning via learning to transfer.
\newblock In {\em ICML}, 2018.

\bibitem{WeinshallCA18}
D.~Weinshall, G.~Cohen, and D.~Amir.
\newblock Curriculum learning by transfer learning: Theory and experiments with
  deep networks.
\newblock In {\em ICML}, 2018.

\bibitem{YangICDM07}
J.~Yang, R.~Yan, and A.~G. Hauptmann.
\newblock Adapting {SVM} classifiers to data with shifted distributions.
\newblock In {\em ICDM Workshops}, 2007.

\bibitem{Lecun2015}
L.~Yann, B.~Yoshua, and H.~Geoffrey.
\newblock Deep learning.
\newblock {\em Nature}, 521(7553):436, 2015.

\bibitem{AmirCVPR18}
A.~R. Zamir, A.~Sax, W.~B. Shen, L.~J. Guibas, J.~Malik, and S.~Savarese.
\newblock Taskonomy: Disentangling task transfer learning.
\newblock In {\em CVPR}, 2018.

\bibitem{ZhangNIPS2018MetaGAN}
R.~Zhang, T.~Che, Z.~Grahahramani, Y.~Bengio, and Y.~Song.
\newblock Metagan: An adversarial approach to few-shot learning.
\newblock In {\em NeurIPS}, 2018.

\end{thebibliography}
