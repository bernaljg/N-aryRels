\section{Conclusion}

In this paper, we carefully examined the recent \ti{CNN}\slash \ti{Daily Mail} reading comprehension task. Our systems demonstrated state-of-the-art results, but more importantly, we performed a careful analysis of the dataset by hand.

Overall, we think the \ti{CNN}\slash \ti{Daily Mail} datasets are valuable datasets, which provide a promising avenue for training effective statistical models for reading comprehension tasks. Nevertheless, we argue that: (i)~this dataset is still quite noisy due to its method of data creation and coreference errors; (ii)~current neural networks have almost reached a performance ceiling on this dataset; and (iii)~the required reasoning and inference level of this dataset is still quite simple.

As future work, we need to consider how we can utilize these datasets (and the models trained upon them) to help solve more complex RC reasoning tasks (with less annotated data).
