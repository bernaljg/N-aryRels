\begin{thebibliography}{}

\bibitem[\protect\citename{Berant \bgroup et al.\egroup
  }2014]{berant2014modeling}
Jonathan Berant, Vivek Srikumar, Pei-Chun Chen, Abby Vander~Linden, Brittany
  Harding, Brad Huang, Peter Clark, and Christopher~D. Manning.
\newblock 2014.
\newblock Modeling biological processes for reading comprehension.
\newblock In {\em Empirical Methods in Natural Language Processing (EMNLP)},
  pages 1499--1510.

\bibitem[\protect\citename{Burges}2013]{burges2013towards}
Christopher~J.C. Burges.
\newblock 2013.
\newblock Towards the machine comprehension of text: An essay.
\newblock Technical report, Microsoft Research Technical Report
  MSR-TR-2013-125.

\bibitem[\protect\citename{Chen and Manning}2014]{chen2014fast}
Danqi Chen and Christopher Manning.
\newblock 2014.
\newblock A fast and accurate dependency parser using neural networks.
\newblock In {\em Empirical Methods in Natural Language Processing (EMNLP)},
  pages 740--750.

\bibitem[\protect\citename{Cho \bgroup et al.\egroup }2014]{cho2014learning}
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi
  Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock 2014.
\newblock Learning phrase representations using rnn encoder--decoder for
  statistical machine translation.
\newblock In {\em Empirical Methods in Natural Language Processing (EMNLP)},
  pages 1724--1734.

\bibitem[\protect\citename{Hermann \bgroup et al.\egroup
  }2015]{hermann2015teaching}
Karl~Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will
  Kay, Mustafa Suleyman, and Phil Blunsom.
\newblock 2015.
\newblock Teaching machines to read and comprehend.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 1684--1692.

\bibitem[\protect\citename{Hill \bgroup et al.\egroup
  }2016]{hill2016goldilocks}
Felix Hill, Antoine Bordes, Sumit Chopra, and Jason Weston.
\newblock 2016.
\newblock The goldilocks principle: Reading children's books with explicit
  memory representations.
\newblock In {\em International Conference on Learning Representations (ICLR)}.

\bibitem[\protect\citename{Kadlec \bgroup et al.\egroup }2016]{kadlec2016text}
Rudolf Kadlec, Martin Schmid, Ondrej Bajgar, and Jan Kleindienst.
\newblock 2016.
\newblock Text understanding with the attention sum reader network.
\newblock In {\em Association for Computational Linguistics (ACL)}.

\bibitem[\protect\citename{Kobayashi \bgroup et al.\egroup
  }2016]{kobayashi2016dynamic}
Sosuke Kobayashi, Ran Tian, Naoaki Okazaki, and Kentaro Inui.
\newblock 2016.
\newblock Dynamic entity representation with max-pooling improves machine
  reading.
\newblock In {\em North American Association for Computational Linguistics
  (NAACL)}.

\bibitem[\protect\citename{Kumar \bgroup et al.\egroup }2016]{kumar2016ask}
Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan
  Gulrajani, Victor Zhong, Romain Paulus, and Richard Socher.
\newblock 2016.
\newblock Ask me anything: Dynamic memory networks for natural language
  processing.
\newblock In {\em International Conference on Machine Learning (ICML)}.

\bibitem[\protect\citename{Lee \bgroup et al.\egroup }2016]{lee2016reasoning}
Moontae Lee, Xiaodong He, Wen-tau Yih, Jianfeng Gao, Li~Deng, and Paul
  Smolensky.
\newblock 2016.
\newblock Reasoning in vector space: An exploratory study of question
  answering.
\newblock In {\em International Conference on Learning Representations (ICLR)}.

\bibitem[\protect\citename{Luong \bgroup et al.\egroup
  }2015]{luong2015effective}
Thang Luong, Hieu Pham, and Christopher~D. Manning.
\newblock 2015.
\newblock Effective approaches to attention-based neural machine translation.
\newblock In {\em Empirical Methods in Natural Language Processing (EMNLP)},
  pages 1412--1421.

\bibitem[\protect\citename{Norvig}1978]{norvig87phd}
Peter Norvig.
\newblock 1978.
\newblock {\em A Unified Theory of Inference for Text Understanding}.
\newblock {Ph.D.} thesis, University of California, Berkeley.

\bibitem[\protect\citename{Pennington \bgroup et al.\egroup
  }2014]{pennington2014glove}
Jeffrey Pennington, Richard Socher, and Christopher Manning.
\newblock 2014.
\newblock Glove: Global vectors for word representation.
\newblock In {\em Empirical Methods in Natural Language Processing (EMNLP)},
  pages 1532--1543.

\bibitem[\protect\citename{Richardson \bgroup et al.\egroup
  }2013]{richardson2013mctest}
Matthew Richardson, Christopher~J.C. Burges, and Erin Renshaw.
\newblock 2013.
\newblock {MCTest}: A challenge dataset for the open-domain machine
  comprehension of text.
\newblock In {\em Empirical Methods in Natural Language Processing (EMNLP)},
  pages 193--203.

\bibitem[\protect\citename{Sachan \bgroup et al.\egroup
  }2015]{sachan2015learning}
Mrinmaya Sachan, Kumar Dubey, Eric Xing, and Matthew Richardson.
\newblock 2015.
\newblock Learning answer-entailing structures for machine comprehension.
\newblock In {\em Association for Computational Linguistics and International
  Joint Conference on Natural Language Processing (ACL/IJCNLP)}, pages
  239--249.

\bibitem[\protect\citename{Sukhbaatar \bgroup et al.\egroup
  }2015]{sukhbaatar2015end}
Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus.
\newblock 2015.
\newblock End-to-end memory networks.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 2431--2439.

\bibitem[\protect\citename{Wang \bgroup et al.\egroup }2015]{wang2015machine}
Hai Wang, Mohit Bansal, Kevin Gimpel, and David McAllester.
\newblock 2015.
\newblock Machine comprehension with syntax, frames, and semantics.
\newblock In {\em Association for Computational Linguistics and International
  Joint Conference on Natural Language Processing (ACL/IJCNLP)}, pages
  700--706.

\bibitem[\protect\citename{Weston \bgroup et al.\egroup
  }2015]{weston2015memory}
Jason Weston, Sumit Chopra, and Antoine Bordes.
\newblock 2015.
\newblock Memory networks.
\newblock In {\em International Conference on Learning Representations (ICLR)}.

\bibitem[\protect\citename{Weston \bgroup et al.\egroup
  }2016]{weston2016towards}
Jason Weston, Antoine Bordes, Sumit Chopra, and Tomas Mikolov.
\newblock 2016.
\newblock Towards {AI}-complete question answering: A set of prerequisite toy
  tasks.
\newblock In {\em International Conference on Learning Representations (ICLR)}.

\bibitem[\protect\citename{Wu \bgroup et al.\egroup }2010]{wu2010adapting}
Qiang Wu, Christopher~J. Burges, Krysta~M. Svore, and Jianfeng Gao.
\newblock 2010.
\newblock Adapting boosting for information retrieval measures.
\newblock {\em Information Retrieval}, pages 254--270.

\end{thebibliography}
